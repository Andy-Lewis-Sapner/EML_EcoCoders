{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Andy-Lewis-Sapner/EML_EcoCoders/blob/main/HW2/HW2_EcoCoders.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RSVP3Dy0IOLT"
      },
      "source": [
        "#Installations, Imports, Dataset Files And Constants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "USgj70mfH0a4",
        "outputId": "39107bd4-5dbf-4624-ad3b-ddea54227729",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.2/54.2 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m323.1/323.1 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m979.6/979.6 kB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.5/11.5 MB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install gradio pykrige -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "AY5necRsH5Po"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.path import Path\n",
        "from matplotlib.spines import Spine\n",
        "from matplotlib.transforms import Affine2D\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import seaborn as sns\n",
        "from pykrige.ok import OrdinaryKriging\n",
        "import gradio as gr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "5XhQsW-DIdpc"
      },
      "outputs": [],
      "source": [
        "pca_data_file = \"https://github.com/Andy-Lewis-Sapner/EML_EcoCoders/raw/main/Data/MeasurmentsAndIndividualsMeanValues.csv\"\n",
        "monitoring_reports_data_file = \"https://github.com/Andy-Lewis-Sapner/EML_EcoCoders/raw/main/Data/KishonRiverMonitoringReports.xlsx\"\n",
        "biogis_data_file = \"https://github.com/Andy-Lewis-Sapner/EML_EcoCoders/raw/main/Data/occurrences.csv\"\n",
        "meteo_data_file = \"https://github.com/Andy-Lewis-Sapner/EML_EcoCoders/raw/main/Data/data_20222024.csv\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Coordinates of monitoring stations (longitude, latitude)\n",
        "station_coords = {\n",
        "    'morad_reservoir_kfar_baruch': (35.193290585018204, 32.63799421872744),\n",
        "    'quarry_station_jalama': (35.0988160806192, 32.72607628851692),\n",
        "    'bridge_iri_yagur': (35.065171162350055, 32.75927717927157),\n",
        "    'gypsum_mountain': (35.0691103835696, 32.777568354869544),\n",
        "    'histadrut_bridge': (35.04857038220264, 32.79873407157874),\n",
        "    'julius_simon_bridge': (35.03488553907516, 32.8016502054031),\n",
        "    'stone_pier': (35.0285340685954, 32.808467653058855),\n",
        "}"
      ],
      "metadata": {
        "id": "jM0KDvqO3wRr"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WPA8PB_3JD5r"
      },
      "source": [
        "# App Logic"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B3pkBzgzJGha"
      },
      "source": [
        "##PCA"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load data"
      ],
      "metadata": {
        "id": "PV9mJcg76reE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "kPFoJ3nyJGEZ"
      },
      "outputs": [],
      "source": [
        "eco_data = pd.read_csv(pca_data_file)\n",
        "eco_data_dates = eco_data['year'].astype(int).astype(str) + '-' + eco_data['month'].astype(int).astype(str)\n",
        "eco_data.insert(0, 'Date', eco_data_dates)\n",
        "eco_data = eco_data.drop(columns=['year', 'month'])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Standardize the data"
      ],
      "metadata": {
        "id": "21U2R6lt6tVW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "YKsjEc6SJbgf"
      },
      "outputs": [],
      "source": [
        "X = eco_data.iloc[:, 1:].values\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use PCA"
      ],
      "metadata": {
        "id": "rUnsXl3v6w5-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "z_cAj42cJepF"
      },
      "outputs": [],
      "source": [
        "# Apply PCA\n",
        "pca = PCA()\n",
        "pca_result = pca.fit_transform(X_scaled)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "l_6q1TzwJgwN"
      },
      "outputs": [],
      "source": [
        "# Create DataFrame with PCA results\n",
        "pca_df = pd.DataFrame(data=pca_result, columns=[f'PC{i+1}' for i in range(X.shape[1])])\n",
        "pca_df['Date'] = eco_data_dates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "uecpD7keJhJE"
      },
      "outputs": [],
      "source": [
        "# Get the loadings (correlation between variables and principal components)\n",
        "loadings = pca.components_.T * np.sqrt(pca.explained_variance_)\n",
        "loadings_df = pd.DataFrame(loadings, columns=[f'PC{i+1}' for i in range(X.shape[1])])\n",
        "loadings_df['Variable'] = eco_data.columns[1:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "1S8mvW02KWMR"
      },
      "outputs": [],
      "source": [
        "feature_names = eco_data.columns[1:]\n",
        "correlation_matrix = eco_data.iloc[:, 1:].corr()\n",
        "explained_variance = pca.explained_variance_ratio_ * 100\n",
        "cumulative_variance = np.cumsum(explained_variance)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scree Plot"
      ],
      "metadata": {
        "id": "M9P5Ok_y61-e"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "KrbTkZNAJmbg"
      },
      "outputs": [],
      "source": [
        "def scree_plot():\n",
        "  scree_plot_fig = plt.figure(figsize=(10, 6))\n",
        "  plt.bar(range(1, len(explained_variance) + 1), explained_variance, alpha=0.7)\n",
        "  plt.plot(range(1, len(explained_variance) + 1), cumulative_variance, 'ro-')\n",
        "  plt.axhline(y=80, color='r', linestyle='--', alpha=0.5)  # Typical threshold line\n",
        "  plt.xlabel('Principal Component')\n",
        "  plt.ylabel('Explained Variance (%)')\n",
        "  plt.title('Scree Plot with Cumulative Variance')\n",
        "  plt.xticks(range(1, len(explained_variance) + 1))\n",
        "  plt.legend(['Cumulative Explained Variance', 'Individual Explained Variance'])\n",
        "  plt.grid(True, alpha=0.3)\n",
        "\n",
        "  plt.close(scree_plot_fig)\n",
        "  return scree_plot_fig"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Biplot for PC1 and PC2"
      ],
      "metadata": {
        "id": "EfZY0G4h630P"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "GmytP7VdJ-3i"
      },
      "outputs": [],
      "source": [
        "def biplot_pc1_pc2():\n",
        "  biplot_fig = plt.figure(figsize=(12, 10))\n",
        "  plt.scatter(pca_result[:, 0], pca_result[:, 1], s=100, alpha=0.7)\n",
        "  for i, site in enumerate(eco_data_dates):\n",
        "    plt.annotate(site, (pca_result[i, 0], pca_result[i, 1]),\n",
        "                 textcoords=\"offset points\", xytext=(0,10), ha='center')\n",
        "  scaling_factor = 5  # Adjust this to scale the arrows appropriately\n",
        "  for i, feature in enumerate(feature_names):\n",
        "      plt.arrow(0, 0,\n",
        "                loadings[i, 0] * scaling_factor,\n",
        "                loadings[i, 1] * scaling_factor,\n",
        "                color='r', alpha=0.7, head_width=0.2)\n",
        "      plt.text(loadings[i, 0] * scaling_factor * 1.15,\n",
        "              loadings[i, 1] * scaling_factor * 1.15,\n",
        "              feature, color='g', ha='center', va='center')\n",
        "\n",
        "  plt.xlabel(f'PC1 ({explained_variance[0]:.2f}%)')\n",
        "  plt.ylabel(f'PC2 ({explained_variance[1]:.2f}%)')\n",
        "  plt.title('PCA Biplot of Ecological Variables')\n",
        "  plt.axhline(y=0, color='k', linestyle='-', alpha=0.3)\n",
        "  plt.axvline(x=0, color='k', linestyle='-', alpha=0.3)\n",
        "  plt.grid(True, alpha=0.3)\n",
        "\n",
        "  plt.close(biplot_fig)\n",
        "  return biplot_fig"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Correlation Matrix"
      ],
      "metadata": {
        "id": "NFTfhRPi66qA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "r5rhSWL7Kh-C"
      },
      "outputs": [],
      "source": [
        "def correlation_matrix_heatmap():\n",
        "  correlation_fig = plt.figure(figsize=(10, 8))\n",
        "  sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', vmin=-1, vmax=1)\n",
        "  plt.title('Correlation Matrix of Ecological Variables')\n",
        "\n",
        "  plt.close(correlation_fig)\n",
        "  return correlation_fig"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loadings Heatmap"
      ],
      "metadata": {
        "id": "o-_49-hv69Es"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "yd2yvMyLKww4"
      },
      "outputs": [],
      "source": [
        "def loadings_heatmap():\n",
        "  loadings_heatmap = pd.DataFrame(pca.components_.T,\n",
        "                              columns=[f'PC{i+1}' for i in range(X.shape[1])],\n",
        "                              index=feature_names)\n",
        "  loadings_fig = plt.figure(figsize=(10, 8))\n",
        "  sns.heatmap(loadings_heatmap, annot=True, cmap='coolwarm', vmin=-1, vmax=1)\n",
        "  plt.title('Variable Contributions to Principal Components')\n",
        "\n",
        "  plt.close(loadings_fig)\n",
        "  return loadings_fig"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Radar Chart"
      ],
      "metadata": {
        "id": "t_7bge7l6_n0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "He7-K50GLAFH"
      },
      "outputs": [],
      "source": [
        "def radar_chart():\n",
        "  # Number of variables\n",
        "  N = len(feature_names)\n",
        "\n",
        "  # What will be the angle of each axis in the plot (divide the plot / number of variables)\n",
        "  angles = [n / float(N) * 2 * np.pi for n in range(N)]\n",
        "  angles += angles[:1]  # Close the loop\n",
        "\n",
        "  # Initialize the figure\n",
        "  fig, ax = plt.subplots(figsize=(10, 10), subplot_kw=dict(polar=True))\n",
        "\n",
        "  # Draw one axis per variable and add labels\n",
        "  plt.xticks(angles[:-1], feature_names, size=12)\n",
        "\n",
        "  # Draw the y axis labels (0-100%)\n",
        "  ax.set_rlabel_position(0)\n",
        "  plt.yticks([0.25, 0.5, 0.75, 1], [\"25%\", \"50%\", \"75%\", \"100%\"], color=\"grey\", size=10)\n",
        "  plt.ylim(0, 1)\n",
        "\n",
        "  # Plot each site\n",
        "  for i, site in enumerate(eco_data['Date']):\n",
        "      values = eco_data.iloc[i, 1:].values  # Get values for this site\n",
        "      # Scale to 0-1 range for each variable\n",
        "      min_vals = eco_data.iloc[:, 1:].min()\n",
        "      max_vals = eco_data.iloc[:, 1:].max()\n",
        "      scaled_values = (values - min_vals) / (max_vals - min_vals)\n",
        "\n",
        "      # Close the loop\n",
        "      scaled_values = np.append(scaled_values, scaled_values.iloc[0])\n",
        "\n",
        "      # Plot values\n",
        "      ax.plot(angles, scaled_values, linewidth=2, linestyle='solid', label=site)\n",
        "      ax.fill(angles, scaled_values, alpha=0.1)\n",
        "\n",
        "  # Add legend\n",
        "  ax.legend(loc='upper right', bbox_to_anchor=(0.1, 0.1))\n",
        "  plt.title('Ecological Characteristics by Date', size=15, y=1.1)\n",
        "\n",
        "  plt.close(fig)\n",
        "  return fig"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PC1, PC2 and PC3 on one Plot"
      ],
      "metadata": {
        "id": "Mi_feFL87B8E"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "oS-LrnT-LZkJ"
      },
      "outputs": [],
      "source": [
        "def pca_3d():\n",
        "  fig = plt.figure(figsize=(12, 10))\n",
        "  ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "  # Plot the observations\n",
        "  ax.scatter(pca_result[:, 0], pca_result[:, 1], pca_result[:, 2], s=100, alpha=0.7)\n",
        "\n",
        "  # Add site labels\n",
        "  for i, site in enumerate(eco_data_dates):\n",
        "      ax.text(pca_result[i, 0], pca_result[i, 1], pca_result[i, 2], site)\n",
        "\n",
        "  ax.set_xlabel(f'PC1 ({explained_variance[0]:.2f}%)')\n",
        "  ax.set_ylabel(f'PC2 ({explained_variance[1]:.2f}%)')\n",
        "  ax.set_zlabel(f'PC3 ({explained_variance[2]:.2f}%)')\n",
        "  ax.set_title('3D PCA Plot of Ecological Data')\n",
        "\n",
        "  plt.close(fig)\n",
        "  return fig"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yO5PrRZQJIlF"
      },
      "source": [
        "##Kriging"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load Data"
      ],
      "metadata": {
        "id": "lv8uUzma7H48"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "URVNccJ5JJzH"
      },
      "outputs": [],
      "source": [
        "monitoring_df = pd.read_excel(monitoring_reports_data_file)\n",
        "monitoring_df['measurement_date'] = pd.to_datetime(monitoring_df['measurement_date'], format='%d/%m/%Y')\n",
        "all_measurement_types = monitoring_df['measurement_type'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "jvM6L5eCL0OM"
      },
      "outputs": [],
      "source": [
        "biogis_df = pd.read_csv(biogis_data_file)\n",
        "biogis_df['collection_date'] = pd.to_datetime(biogis_df['collection_date'], format='%d/%m/%Y')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Find Best Kriging Variogram Model"
      ],
      "metadata": {
        "id": "XZhIeJmV7JcN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find_best_model(x, y, values, xpoints, ypoints, models=('linear', 'power', 'gaussian', 'spherical', 'exponential')):\n",
        "    best_model = None\n",
        "    best_score = float('inf')\n",
        "    best_ok = None\n",
        "    best_z, best_ss = None, None\n",
        "\n",
        "    for model in models:\n",
        "        try:\n",
        "            ok = OrdinaryKriging(\n",
        "                x, y, values,\n",
        "                variogram_model=model,\n",
        "                coordinates_type='geographic',\n",
        "                verbose=False,\n",
        "                enable_plotting=False\n",
        "            )\n",
        "            z, ss = ok.execute('grid', xpoints, ypoints)\n",
        "            # Use the sum of squared values as a crude proxy for quality\n",
        "            score = np.nansum(ss)\n",
        "            if score < best_score:\n",
        "                best_score = score\n",
        "                best_model = model\n",
        "                best_z, best_ss = z, ss\n",
        "                best_ok = ok\n",
        "\n",
        "        except Exception as e:\n",
        "            # print(f\"Model {model} failed: {e}\")\n",
        "            continue\n",
        "\n",
        "    return best_ok, best_z, best_ss"
      ],
      "metadata": {
        "id": "2S0qpW0MD9lg"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot Kriging"
      ],
      "metadata": {
        "id": "vlZKNriI7O5y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "Wk5_W6ekL_bq"
      },
      "outputs": [],
      "source": [
        "def plot_ordinary_kriging(kriging_longitudes, kriging_latitudes, kriging_values, measurement_type_to_krig):\n",
        "  plots = []\n",
        "  if len(kriging_values) >= 3:\n",
        "    # Create a grid for prediction (adjust the range based on your coordinates)\n",
        "    grid_lon = np.linspace(kriging_longitudes.min() - 0.05, kriging_longitudes.max() + 0.05, 100)\n",
        "    grid_lat = np.linspace(kriging_latitudes.min() - 0.05, kriging_latitudes.max() + 0.05, 100)\n",
        "\n",
        "    # Perform Ordinary Kriging\n",
        "    # ok = OrdinaryKriging(\n",
        "    #     kriging_longitudes,\n",
        "    #     kriging_latitudes,\n",
        "    #     kriging_values,\n",
        "    #     variogram_model='spherical',  # You can experiment with other models\n",
        "    #     verbose=False,\n",
        "    #     enable_plotting=False,\n",
        "    # )\n",
        "\n",
        "    ok, z, ss = find_best_model(kriging_longitudes, kriging_latitudes, kriging_values, grid_lon, grid_lat)\n",
        "\n",
        "    # Make predictions on the grid\n",
        "    # z, ss = ok.execute('grid', grid_lon, grid_lat)\n",
        "\n",
        "    # Plotting the results\n",
        "    fig_interpolation = plt.figure(figsize=(10, 8))\n",
        "\n",
        "    # Contour plot of the Kriged values\n",
        "    contour = plt.contourf(grid_lon, grid_lat, z, levels=20, cmap='viridis')\n",
        "    cbar = plt.colorbar(contour, label=f'Predicted {measurement_type_to_krig}')\n",
        "\n",
        "    # Scatter plot of the original data points\n",
        "    plt.scatter(kriging_longitudes, kriging_latitudes, c=kriging_values, cmap='viridis', edgecolor='k', s=50)\n",
        "    plt.title(f'Ordinary Kriging Interpolation of {measurement_type_to_krig}')\n",
        "    plt.xlabel('Longitude')\n",
        "    plt.ylabel('Latitude')\n",
        "    plt.colorbar(label=f'{measurement_type_to_krig} Level')\n",
        "    plt.axis('equal')\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "    plt.close(fig_interpolation)\n",
        "    plots.append(fig_interpolation)\n",
        "\n",
        "    # Optional: Plot the variance (estimation error)\n",
        "    fig_variations = plt.figure(figsize=(10, 8))\n",
        "    contour_var = plt.contourf(grid_lon, grid_lat, ss, levels=20, cmap='plasma_r')\n",
        "    cbar_var = plt.colorbar(contour_var, label='Kriging Variance')\n",
        "    plt.scatter(kriging_longitudes, kriging_latitudes, c='black', edgecolor='white', s=50)\n",
        "    plt.title(f'Ordinary Kriging Variance for {measurement_type_to_krig}')\n",
        "    plt.xlabel('Longitude')\n",
        "    plt.ylabel('Latitude')\n",
        "    plt.axis('equal')\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "    plt.close(fig_variations)\n",
        "    plots.append(fig_variations)\n",
        "\n",
        "  return plots"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot Kriging using Data"
      ],
      "metadata": {
        "id": "QdjIKCfZ7aN3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_kriging_at(year, month, data_source, measurement_type):\n",
        "    \"\"\"\n",
        "    Plots Ordinary Kriging interpolation for a given year and month,\n",
        "    using a specified data source and measurement type.\n",
        "\n",
        "    Args:\n",
        "        year (int): The year of the data.\n",
        "        month (int): The month of the data.\n",
        "        data_source (pd.DataFrame): The DataFrame containing the data\n",
        "                                     (either monitoring_df or biogis_df).\n",
        "        measurement_type (str): The type of measurement to krig\n",
        "                                (e.g., 'coliform_bacteria' or 'individuals').\n",
        "\n",
        "    Returns:\n",
        "        list: A list of matplotlib figure objects (interpolation and variance plots),\n",
        "              or [None, None] if not enough data points are available.\n",
        "    \"\"\"\n",
        "    if data_source is monitoring_df:\n",
        "        filtered_data = data_source[\n",
        "            (data_source['measurement_date'].dt.year == year) &\n",
        "            (data_source['measurement_date'].dt.month == month) &\n",
        "            (data_source['measurement_type'] == measurement_type)\n",
        "        ]\n",
        "\n",
        "        kriging_longitudes = []\n",
        "        kriging_latitudes = []\n",
        "        kriging_values = []\n",
        "\n",
        "        for station, coords in station_coords.items():\n",
        "            if station in filtered_data.columns and not pd.isna(filtered_data[station].iloc[0]):\n",
        "                kriging_longitudes.append(coords[0])\n",
        "                kriging_latitudes.append(coords[1])\n",
        "                kriging_values.append(filtered_data[station].iloc[0])\n",
        "\n",
        "        kriging_longitudes = np.array(kriging_longitudes)\n",
        "        kriging_latitudes = np.array(kriging_latitudes)\n",
        "        kriging_values = np.array(kriging_values)\n",
        "\n",
        "    elif data_source is biogis_df:\n",
        "        filtered_data = data_source[\n",
        "            (data_source['collection_date'].dt.year == year) &\n",
        "             (data_source['collection_date'].dt.month == month)\n",
        "        ]\n",
        "\n",
        "        aggregated_individuals = filtered_data.groupby(['longitude', 'latitude'])[measurement_type].sum().reset_index()\n",
        "        kriging_longitudes = aggregated_individuals['longitude'].values\n",
        "        kriging_latitudes = aggregated_individuals['latitude'].values\n",
        "        kriging_values = aggregated_individuals[measurement_type].values\n",
        "\n",
        "    else:\n",
        "        return [None, None] # Unsupported data source\n",
        "\n",
        "    plots = plot_ordinary_kriging(kriging_longitudes, kriging_latitudes, kriging_values, measurement_type)\n",
        "\n",
        "    if not plots:\n",
        "        return [None, None]\n",
        "    return plots"
      ],
      "metadata": {
        "id": "wFcE__OZ_HDl"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Intervining Variables"
      ],
      "metadata": {
        "id": "1io87_TP_wsz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read and Process Data"
      ],
      "metadata": {
        "id": "9WfZol3m7qwz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read meteorological data\n",
        "meteo_data = pd.read_csv(meteo_data_file)\n",
        "\n",
        "# Rename columns (from Hebrew to English)\n",
        "meteo_data = meteo_data.rename(columns={\n",
        "    meteo_data.columns[0]: 'station',\n",
        "    meteo_data.columns[1]: 'date',\n",
        "    meteo_data.columns[2]: 'temperature',\n",
        "    meteo_data.columns[3]: 'wind_velocity'\n",
        "})\n",
        "\n",
        "# Convert date column to datetime and extract month and year\n",
        "meteo_data['date'] = pd.to_datetime(meteo_data['date'], format=\"%d-%m-%Y %H:%M\")\n",
        "meteo_data['month'] = meteo_data['date'].dt.month\n",
        "meteo_data['year'] = meteo_data['date'].dt.year\n",
        "meteo_data.drop(columns=['date'], inplace=True)"
      ],
      "metadata": {
        "id": "8k-bnrjo_xMz"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "min_year = meteo_data['year'].min()\n",
        "max_year = meteo_data['year'].max()\n",
        "\n",
        "temperatures = [meteo_data[(meteo_data['year'] == year) & (meteo_data['month'] == month)]['temperature'].max() for year in range(min_year, max_year + 1) for month in range(1, 13)]\n",
        "wind_velocities = [meteo_data[(meteo_data['year'] == year) & (meteo_data['month'] == month)]['wind_velocity'].max() for year in range(min_year, max_year + 1) for month in range(1, 13)]\n",
        "\n",
        "max_temperature_idx = meteo_data['temperature'].idxmax()\n",
        "max_wind_velocity_idx = meteo_data['wind_velocity'].idxmax()"
      ],
      "metadata": {
        "id": "aUDUafnE_39Q"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot Data"
      ],
      "metadata": {
        "id": "_J53ZXsY7uDf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_meteo_data_per_month():\n",
        "  months = [f\"{year}-{month:02d}\" for year in range(min_year, max_year + 1) for month in range(1, 13)]\n",
        "  max_temperature_month = f\"{meteo_data.loc[max_temperature_idx]['year']}-{meteo_data.iloc[max_temperature_idx]['month']:02d}\"\n",
        "  max_wind_velocity_month = f\"{meteo_data.loc[max_wind_velocity_idx]['year']}-{meteo_data.iloc[max_wind_velocity_idx]['month']:02d}\"\n",
        "\n",
        "  fig1 = plt.figure(figsize=(12, 8))\n",
        "  plt.plot(months, temperatures, label='Max Temperature', marker='o')\n",
        "  plt.plot(max_temperature_month, meteo_data.loc[max_temperature_idx]['temperature'], 'ro', label='Max Temperature (Point)')\n",
        "  plt.xlabel('Month')\n",
        "  plt.xticks(rotation=270)\n",
        "  plt.ylabel('Temperature (°C)')\n",
        "  plt.title('Max Temperature per Month')\n",
        "  plt.grid(True)\n",
        "  plt.legend()\n",
        "\n",
        "  fig2 = plt.figure(figsize=(12, 8))\n",
        "  plt.plot(months, wind_velocities, label='Max Wind Velocity', marker='o')\n",
        "  plt.plot(max_wind_velocity_month, meteo_data.loc[max_wind_velocity_idx]['wind_velocity'], 'ro', label='Max Wind Velocity (Point)')\n",
        "  plt.xlabel('Month')\n",
        "  plt.xticks(rotation=270)\n",
        "  plt.ylabel('Wind Velocity (m/s)')\n",
        "  plt.title('Max Wind Velocity per Month')\n",
        "  plt.grid(True)\n",
        "  plt.legend()\n",
        "\n",
        "  plt.close(fig1)\n",
        "  plt.close(fig2)\n",
        "\n",
        "  return [fig1, fig2]"
      ],
      "metadata": {
        "id": "ia73-mE9_6xb"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Scenarios"
      ],
      "metadata": {
        "id": "-mxYcaYQ_MKs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Base Scenario"
      ],
      "metadata": {
        "id": "jYlhtlgN_NpR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_kriging_base(measurement_type):\n",
        "  # Determine the year and month for the latest biogis data\n",
        "  latest_date = biogis_df['collection_date'].max()\n",
        "  year = latest_date.year\n",
        "  month = latest_date.month\n",
        "  individuals_plots = plot_kriging_at(year, month, biogis_df, 'individuals')\n",
        "\n",
        "  # Determine the year and month for the latest monitoring data\n",
        "  latest_date = monitoring_df['measurement_date'].max()\n",
        "  year = latest_date.year\n",
        "  month = latest_date.month\n",
        "  measurement_type_plots = plot_kriging_at(year, month, monitoring_df, measurement_type)\n",
        "\n",
        "  plots = individuals_plots + measurement_type_plots\n",
        "  return plots"
      ],
      "metadata": {
        "id": "v_Ykz5QMLP1_"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pressured Scenario"
      ],
      "metadata": {
        "id": "sNGUqQqq_lZH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_kriging_at_pressure(measurement_type):\n",
        "  year = meteo_data.loc[max_wind_velocity_idx]['year']\n",
        "  month = meteo_data.loc[max_wind_velocity_idx]['month']\n",
        "\n",
        "  individuals_plots = plot_kriging_at(year, month, biogis_df, 'individuals')\n",
        "  measurement_type_plots = plot_kriging_at(year, month, monitoring_df, measurement_type)\n",
        "\n",
        "  plots = individuals_plots + measurement_type_plots\n",
        "  return plots"
      ],
      "metadata": {
        "id": "_MNMMa0M3-aw"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Rehabilitaion Scenario"
      ],
      "metadata": {
        "id": "8UfbJ5rz_oJE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_kriging_at_rehabilitation(measurement_type):\n",
        "  year = meteo_data.loc[max_temperature_idx]['year']\n",
        "  month = meteo_data.loc[max_temperature_idx]['month'] + 1\n",
        "  if month > 12:\n",
        "    month = 1\n",
        "    year += 1\n",
        "\n",
        "  individuals_plots = plot_kriging_at(year, month, biogis_df, 'individuals')\n",
        "  measurement_type_plots = plot_kriging_at(year, month, monitoring_df, measurement_type)\n",
        "\n",
        "  plots = individuals_plots + measurement_type_plots\n",
        "  return plots"
      ],
      "metadata": {
        "id": "qfVD4oSo4r7U"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98Pm2yGKM8R1"
      },
      "source": [
        "## Gradio Interface"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "za8wKApZKg79"
      },
      "outputs": [],
      "source": [
        "def plot_pca(plot_type):\n",
        "  if plot_type == \"Scree Plot\":\n",
        "    return scree_plot()\n",
        "  elif plot_type == \"Biplot (PC1 vs PC2)\":\n",
        "    return biplot_pc1_pc2()\n",
        "  elif plot_type == \"Correlation Matrix\":\n",
        "    return correlation_matrix_heatmap()\n",
        "  elif plot_type == \"PCA Loadings Heatmap\":\n",
        "    return loadings_heatmap()\n",
        "  elif plot_type == \"Radar Chart\":\n",
        "    return radar_chart()\n",
        "  elif plot_type == \"3D PCA Plot\":\n",
        "    return pca_3d()\n",
        "  return None"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_kriging_at_scenario(scenario, measurement_type):\n",
        "  if scenario == \"Base Scenario\":\n",
        "    return plot_kriging_base(measurement_type)\n",
        "  elif scenario == \"Pressure Scenario\":\n",
        "    return plot_kriging_at_pressure(measurement_type)\n",
        "  elif scenario == \"Rehabilitation Scenario\":\n",
        "    return plot_kriging_at_rehabilitation(measurement_type)\n",
        "  return None"
      ],
      "metadata": {
        "id": "1EZXDwZz8CSw"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "M4DsITTgF76I"
      },
      "outputs": [],
      "source": [
        "with gr.Blocks() as demo:\n",
        "    with gr.Tabs():\n",
        "        with gr.Tab(\"DataFrames\"):\n",
        "          with gr.Row():\n",
        "            with gr.Column():\n",
        "              gr.Markdown(\"### Ecological PCA Data\")\n",
        "              gr.DataFrame(eco_data)\n",
        "\n",
        "            with gr.Column():\n",
        "              gr.Markdown(\"### Biogis Observations\")\n",
        "              gr.DataFrame(biogis_df)\n",
        "\n",
        "          with gr.Row():\n",
        "            with gr.Column():\n",
        "              gr.Markdown(\"### Monitoring Reports\")\n",
        "              gr.DataFrame(monitoring_df)\n",
        "\n",
        "            with gr.Column():\n",
        "              gr.Markdown(\"### Meteo Data\")\n",
        "              gr.DataFrame(meteo_data)\n",
        "\n",
        "          with gr.Row():\n",
        "            meteo_figs = plot_meteo_data_per_month()\n",
        "            if meteo_figs[0]:\n",
        "              with gr.Column():\n",
        "                gr.Markdown(\"### Max Temperature per Month\")\n",
        "                gr.Plot(lambda: meteo_figs[0])\n",
        "              with gr.Column():\n",
        "                gr.Markdown(\"### Max Wind Velocity per Month\")\n",
        "                gr.Plot(lambda: meteo_figs[1])\n",
        "\n",
        "        with gr.Tab(\"PCA Plots\"):\n",
        "          with gr.Row():\n",
        "            plot_dropdown = gr.Dropdown(choices=[\"Scree Plot\", \"Biplot (PC1 vs PC2)\", \"Correlation Matrix\", \"PCA Loadings Heatmap\", \"Radar Chart\", \"3D PCA Plot\"], label=\"Select Plot\", value=\"Scree Plot\")\n",
        "\n",
        "          with gr.Row():\n",
        "            plot_output = gr.Plot()\n",
        "\n",
        "          plot_dropdown.change(\n",
        "              fn=plot_pca,\n",
        "              inputs=[plot_dropdown],\n",
        "              outputs=[plot_output],\n",
        "          )\n",
        "\n",
        "          demo.load(fn=plot_pca, inputs=[plot_dropdown], outputs=[plot_output])\n",
        "\n",
        "        with gr.Tab(\"Kriging Plots\"):\n",
        "            with gr.Row():\n",
        "              kriging_plot_dropdown = gr.Dropdown(choices=[\"Base Scenario\", \"Pressure Scenario\", \"Rehabilitation Scenario\"], label=\"Select Scenario\", value=\"Base Scenario\")\n",
        "              measurement_type_for_kriging = gr.Dropdown(choices=list(all_measurement_types), label=\"Select Measurement Type\", value=all_measurement_types[0])\n",
        "            with gr.Row():\n",
        "              create_kriging_plots_button = gr.Button(\"Create Kriging Plots\", scale=1, min_width=0)\n",
        "\n",
        "            gr.Markdown(\"### Individuals Kriging\")\n",
        "            with gr.Row():\n",
        "              with gr.Column():\n",
        "                kriging_individuals_plot1 = gr.Plot()\n",
        "              with gr.Column():\n",
        "                kriging_individuals_plot2 = gr.Plot()\n",
        "\n",
        "            gr.Markdown(\"### Measurement Kriging\")\n",
        "            with gr.Row():\n",
        "              with gr.Column():\n",
        "                kriging_coliform_plot1 = gr.Plot()\n",
        "              with gr.Column():\n",
        "                kriging_coliform_plot2 = gr.Plot()\n",
        "\n",
        "            create_kriging_plots_button.click(\n",
        "                fn=plot_kriging_at_scenario,\n",
        "                inputs=[kriging_plot_dropdown, measurement_type_for_kriging],\n",
        "                outputs=[kriging_individuals_plot1, kriging_individuals_plot2, kriging_coliform_plot1, kriging_coliform_plot2]\n",
        "            )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lpTZdyo2NVno"
      },
      "source": [
        "# App"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 650
        },
        "id": "QIlquiiXNX6a",
        "outputId": "fc4db4c1-1903-49ab-95a2-bacfc6262a2d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://a04d7d293b72a4a890.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://a04d7d293b72a4a890.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "demo.launch()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "WPA8PB_3JD5r",
        "B3pkBzgzJGha",
        "yO5PrRZQJIlF",
        "98Pm2yGKM8R1"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}