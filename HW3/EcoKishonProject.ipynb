{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Andy-Lewis-Sapner/EML_EcoCoders/blob/main/HW3/EcoKishonProject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t21r1DDMvdBh"
      },
      "source": [
        "# Installations, Imports, Enums and Constants"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qt9X970i1I7e"
      },
      "source": [
        "https://github.com/Andy-Lewis-Sapner/EML_EcoCoders\n",
        "\n",
        "https://en.wikipedia.org/api/rest_v1/page/summary/{title}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6xL2Vk0utibA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f896ceb9-7e05-44ab-ba05-9bc1b515931e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m979.6/979.6 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install gradio pykrige -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ce3Yp0Jw4Jp"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "from enum import Enum\n",
        "import folium\n",
        "import geopandas as gpd\n",
        "import gradio as gr\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import plotly\n",
        "import plotly.express as px\n",
        "from pykrige.ok import OrdinaryKriging\n",
        "import requests\n",
        "import seaborn as sns\n",
        "from shapely.geometry import Point\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "import xgboost as xgb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4aVN-tT-w3-w"
      },
      "outputs": [],
      "source": [
        "kishon_occurences_data_file = \"https://github.com/Andy-Lewis-Sapner/EML_EcoCoders/raw/main/Data/gbif_kishon_data_occurences.csv\"\n",
        "kishon_measurements_file = \"https://github.com/Andy-Lewis-Sapner/EML_EcoCoders/raw/main/Data/KishonRiverMonitoringReports.xlsx\"\n",
        "pca_data_file = \"https://github.com/Andy-Lewis-Sapner/EML_EcoCoders/raw/main/Data/MeasurmentsAndIndividualsMeanValues.csv\"\n",
        "monitoring_reports_data_file = \"https://github.com/Andy-Lewis-Sapner/EML_EcoCoders/raw/main/Data/KishonRiverMonitoringReports.xlsx\"\n",
        "measurments_and_individuals_file = \"https://github.com/Andy-Lewis-Sapner/EML_EcoCoders/raw/main/Data/MeasurmentsAndIndividuals.csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oz4_43MDMp3O"
      },
      "outputs": [],
      "source": [
        "station_coords = {\n",
        "    'morad_reservoir_kfar_baruch': (35.193290585018204, 32.63799421872744),\n",
        "    'quarry_station_jalama': (35.0988160806192, 32.72607628851692),\n",
        "    'bridge_iri_yagur': (35.065171162350055, 32.75927717927157),\n",
        "    'gypsum_mountain': (35.0691103835696, 32.777568354869544),\n",
        "    'histadrut_bridge': (35.04857038220264, 32.79873407157874),\n",
        "    'julius_simon_bridge': (35.03488553907516, 32.8016502054031),\n",
        "    'stone_pier': (35.0285340685954, 32.808467653058855),\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Py1h8DKQ0Zj"
      },
      "outputs": [],
      "source": [
        "class Month(Enum):\n",
        "  Jan = 1\n",
        "  Feb = 2\n",
        "  Mar = 3\n",
        "  Apr = 4\n",
        "  May = 5\n",
        "  Jun = 6\n",
        "  Jul = 7\n",
        "  Aug = 8\n",
        "  Sep = 9\n",
        "  Oct = 10\n",
        "  Nov = 11\n",
        "  Dec = 12\n",
        "\n",
        "class Measurement(Enum):  # strings have to be as writen in the csv file (except of total populations)\n",
        "  Total_populations = \"total_populations\"\n",
        "  Specific_electrical_conductivity = \"specific_electrical_conductivity\"\n",
        "  ph = \"ph_value\"\n",
        "  Dissolved_oxygen = \"dissolved_oxygen_saturation_percentage\"\n",
        "  Temperature = \"temperature\"\n",
        "  Opacity = \"opacity\"\n",
        "  Coliform_bacteria = \"coliform_bacteria\"\n",
        "\n",
        "measurements_size = len(Measurement)\n",
        "\n",
        "class Color(Enum):\n",
        "  Red = \"red\"\n",
        "  Green = \"green\"\n",
        "  Blue = \"blue\"\n",
        "  Yellow = \"yellow\"\n",
        "  Purple = \"purple\"\n",
        "  Orange = \"orange\"\n",
        "  Grey = \"grey\"\n",
        "  Brown = \"brown\"\n",
        "  Pink = \"pink\"\n",
        "\n",
        "class Station(Enum):\n",
        "  morad_reservoir_kfar_baruch = \"morad_reservoir_kfar_baruch\"\n",
        "  quarry_station_jalama = \"quarry_station_jalama\"\n",
        "  bridge_iri_yagur = \"bridge_iri_yagur\"\n",
        "  gypsum_mountain = \"gypsum_mountain\"\n",
        "  histadrut_bridge = \"histadrut_bridge\"\n",
        "  julius_simon_bridge = \"julius_simon_bridge\"\n",
        "  stone_pier = \"stone_pier\"\n",
        "\n",
        "# setting enums as lists for later use\n",
        "measurement_list = list(Measurement)\n",
        "color_list = list(Color)\n",
        "station_list = list(Station)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vT8wjUNkw0iM"
      },
      "source": [
        "# Data Analysis\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pywW_H390UiG"
      },
      "source": [
        "Show Datasets, PCA and Kriging"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "af_mHKQfxe_B"
      },
      "source": [
        "## Logic"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "kishon_occurences = pd.read_csv(kishon_occurences_data_file)\n",
        "kishon_measurements = pd.read_excel(kishon_measurements_file)"
      ],
      "metadata": {
        "id": "he6j97gwKE4G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "measurements_needed = ['specific_electrical_conductivity', 'opacity', 'coliform_bacteria', 'dissolved_oxygen_saturaion_percentage', 'opacity', 'ph_value', 'specific_electrical_conductivity', 'temperature']\n",
        "\n",
        "# Filter the dataframe to include only 'specific_electrical_conductivity' and 'opacity'\n",
        "# filtered_df = kishon_measurements[kishon_measurements['measurement_type'].isin(['specific_electrical_conductivity', 'opacity', 'coliform_bacteria'])].copy()\n",
        "filtered_df = kishon_measurements[kishon_measurements['measurement_type'].isin(measurements_needed)].copy()\n",
        "\n",
        "# Extract year and month from the 'measurement_date' column\n",
        "filtered_df['year'] = pd.to_datetime(filtered_df['measurement_date']).dt.year\n",
        "filtered_df['month'] = pd.to_datetime(filtered_df['measurement_date']).dt.month\n",
        "\n",
        "# Define the list of station columns\n",
        "station_columns = ['morad_reservoir_kfar_baruch', 'quarry_station_jalama', 'bridge_iri_yagur', 'gypsum_mountain', 'histadrut_bridge', 'julius_simon_bridge', 'stone_pier']\n",
        "\n",
        "# Melt the dataframe to have station names as a column\n",
        "melted_df = filtered_df.melt(\n",
        "    id_vars=['year', 'month', 'measurement_type'],\n",
        "    value_vars=station_columns,\n",
        "    var_name='station',\n",
        "    value_name='measurement_value'\n",
        ")\n",
        "\n",
        "# Group by year, month, measurement type, and station, and calculate the mean\n",
        "mean_measurements = melted_df.groupby(['year', 'month', 'measurement_type'])['measurement_value'].mean().reset_index()\n",
        "\n",
        "# Pivot the table to have measurement_type as columns\n",
        "mean_measurements_pivot = mean_measurements.pivot_table(\n",
        "    index=['year', 'month'],\n",
        "    columns='measurement_type',\n",
        "    values='measurement_value'\n",
        ").reset_index()\n",
        "\n",
        "# Create the new dataframe with the calculated means\n",
        "measurements_kishon = mean_measurements_pivot\n",
        "kishon_occurences_per_year_month = kishon_occurences.groupby(['year', 'month'])['individualCount'].sum().reset_index()\n",
        "merged_df = measurements_kishon.merge(kishon_occurences_per_year_month, on=['year', 'month'], how='inner')"
      ],
      "metadata": {
        "id": "ofaAdxZZKTf_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tF14hES_Q4SO"
      },
      "source": [
        "###PCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z0DcEFOvw3T0"
      },
      "outputs": [],
      "source": [
        "# Load Data\n",
        "# eco_data = pd.read_csv(pca_data_file)\n",
        "eco_data = merged_df.copy()\n",
        "eco_data_dates = eco_data['year'].astype(int).astype(str) + '-' + eco_data['month'].astype(int).astype(str)\n",
        "eco_data.insert(0, 'Date', eco_data_dates)\n",
        "# Dropping rows with NaN values before PCA\n",
        "eco_data = eco_data[~eco_data.isnull().any(axis=1)]\n",
        "\n",
        "# Align eco_data_dates with the index of eco_data after dropping NaNs\n",
        "eco_data_dates_aligned = eco_data['Date']\n",
        "\n",
        "# Drop original year and month columns as 'Date' is now present\n",
        "eco_data = eco_data.drop(columns=['year', 'month'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aunqIe5CQ7UK"
      },
      "outputs": [],
      "source": [
        "# Standardize Data\n",
        "X = eco_data.iloc[:, 1:].values\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sk1hsgnnQ8d_"
      },
      "outputs": [],
      "source": [
        "# Apply PCA\n",
        "pca = PCA()\n",
        "pca_result = pca.fit_transform(X_scaled)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BDN4lr4wRnvp"
      },
      "outputs": [],
      "source": [
        "# Create DataFrame with PCA results\n",
        "pca_df = pd.DataFrame(data=pca_result, columns=[f'PC{i+1}' for i in range(X.shape[1])])\n",
        "pca_df['Date'] = eco_data_dates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-mY7Rw7qRoy6"
      },
      "outputs": [],
      "source": [
        "# Get the loadings (correlation between variables and principal components)\n",
        "loadings = pca.components_.T * np.sqrt(pca.explained_variance_)\n",
        "loadings_df = pd.DataFrame(loadings, columns=[f'PC{i+1}' for i in range(X.shape[1])])\n",
        "loadings_df['Variable'] = eco_data.columns[1:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IvW51t0rRp0T"
      },
      "outputs": [],
      "source": [
        "feature_names = eco_data.columns[1:]\n",
        "correlation_matrix = eco_data.iloc[:, 1:].corr()\n",
        "explained_variance = pca.explained_variance_ratio_ * 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "80QjpJQORsOJ"
      },
      "outputs": [],
      "source": [
        "def biplot_pc1_pc2():\n",
        "  biplot_fig = plt.figure(figsize=(12, 10))\n",
        "  # Use the aligned eco_data_dates for annotation\n",
        "  plt.scatter(pca_result[:, 0], pca_result[:, 1], s=100, alpha=0.7)\n",
        "  for i, site in enumerate(eco_data_dates_aligned): # Use the aligned dates\n",
        "    plt.annotate(site, (pca_result[i, 0], pca_result[i, 1]),\n",
        "                 textcoords=\"offset points\", xytext=(0,10), ha='center')\n",
        "  scaling_factor = 5  # Adjust this to scale the arrows appropriately\n",
        "  for i, feature in enumerate(feature_names):\n",
        "      plt.arrow(0, 0,\n",
        "                loadings[i, 0] * scaling_factor,\n",
        "                loadings[i, 1] * scaling_factor,\n",
        "                color='r', alpha=0.7, head_width=0.2)\n",
        "      plt.text(loadings[i, 0] * scaling_factor * 1.15,\n",
        "              loadings[i, 1] * scaling_factor * 1.15,\n",
        "              feature, color='g', ha='center', va='center')\n",
        "\n",
        "  plt.xlabel(f'PC1 ({explained_variance[0]:.2f}%)')\n",
        "  plt.ylabel(f'PC2 ({explained_variance[1]:.2f}%)')\n",
        "  plt.title('PCA Biplot of Ecological Variables')\n",
        "  plt.axhline(y=0, color='k', linestyle='-', alpha=0.3)\n",
        "  plt.axvline(x=0, color='k', linestyle='-', alpha=0.3)\n",
        "  plt.grid(True, alpha=0.3)\n",
        "\n",
        "  plt.tight_layout()\n",
        "  plt.close(biplot_fig)\n",
        "  return biplot_fig"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def correlation_matrix_heatmap():\n",
        "  # Creates a heatmap of the correlation matrix.\n",
        "  correlation_fig = plt.figure(figsize=(10, 8))\n",
        "  sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', vmin=-1, vmax=1)\n",
        "  plt.title('Correlation Matrix of Ecological Variables')\n",
        "  plt.tight_layout()\n",
        "  plt.close(correlation_fig)\n",
        "  return correlation_fig"
      ],
      "metadata": {
        "id": "7ZKmzSC1Lh64"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oy-LCxPZSbTD"
      },
      "source": [
        "###Kriging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QDkp5jtbSccD"
      },
      "outputs": [],
      "source": [
        "monitoring_df = pd.read_excel(monitoring_reports_data_file)\n",
        "monitoring_df['measurement_date'] = pd.to_datetime(monitoring_df['measurement_date'], format='%d/%m/%Y')\n",
        "all_measurement_types = monitoring_df['measurement_type'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w7YhUmi-SfBS"
      },
      "outputs": [],
      "source": [
        "occurences_df = pd.read_csv(kishon_occurences_data_file)\n",
        "occurences_df['collection_date'] = pd.to_datetime(occurences_df['year'].astype(str) + '-' + occurences_df['month'].astype(str) + '-01')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gTVqyZbkSsKr"
      },
      "outputs": [],
      "source": [
        "def find_best_model(x, y, values, xpoints, ypoints, models=('linear', 'power', 'gaussian', 'spherical', 'exponential')):\n",
        "    best_model = None\n",
        "    best_score = float('inf')\n",
        "    best_ok = None\n",
        "    best_z, best_ss = None, None\n",
        "\n",
        "    for model in models:\n",
        "        try:\n",
        "            ok = OrdinaryKriging(\n",
        "                x, y, values,\n",
        "                variogram_model=model,\n",
        "                coordinates_type='geographic',\n",
        "                verbose=False,\n",
        "                enable_plotting=False\n",
        "            )\n",
        "            z, ss = ok.execute('grid', xpoints, ypoints)\n",
        "\n",
        "            if z is None or z.ndim != 2 or ss is None or ss.ndim != 2:\n",
        "                continue # Skip this model if output is not 2D\n",
        "\n",
        "            # Use the sum of squared values as a crude proxy for quality\n",
        "            score = np.nansum(ss)\n",
        "            if score < best_score:\n",
        "                best_score = score\n",
        "                best_model = model\n",
        "                best_z, best_ss = z, ss\n",
        "                best_ok = ok\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Model '{model}' failed with error: {e}\")\n",
        "            continue\n",
        "\n",
        "    # Check if a valid model was found that produced 2D output\n",
        "    if best_z is None or best_ss is None:\n",
        "        print(\"No variogram model produced valid 2D Kriging output.\")\n",
        "        return None, None, None # Return None if no valid 2D output was found\n",
        "\n",
        "    return best_ok, best_z, best_ss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OR9iES6ISuB_"
      },
      "outputs": [],
      "source": [
        "def plot_ordinary_kriging(kriging_longitudes, kriging_latitudes, kriging_values, measurement_type_to_krig):\n",
        "  plots = []\n",
        "  if len(kriging_values) >= 3:\n",
        "    # Create a grid for prediction (adjust the range based on your coordinates)\n",
        "    grid_lon = np.linspace(kriging_longitudes.min() - 0.05, kriging_longitudes.max() + 0.05, 100)\n",
        "    grid_lat = np.linspace(kriging_latitudes.min() - 0.05, kriging_latitudes.max() + 0.05, 100)\n",
        "\n",
        "    ok, z, ss = find_best_model(kriging_longitudes, kriging_latitudes, kriging_values, grid_lon, grid_lat)\n",
        "\n",
        "    if ok is None or z is None or ss is None:\n",
        "      return [None, None]\n",
        "\n",
        "    # Plotting the results\n",
        "    fig_interpolation = plt.figure(figsize=(10, 8))\n",
        "\n",
        "    # Contour plot of the Kriged values\n",
        "    contour = plt.contourf(grid_lon, grid_lat, z, levels=20, cmap='viridis')\n",
        "    cbar = plt.colorbar(contour, label=f'Predicted {measurement_type_to_krig}')\n",
        "\n",
        "    # Scatter plot of the original data points\n",
        "    plt.scatter(kriging_longitudes, kriging_latitudes, c=kriging_values, cmap='viridis', edgecolor='k', s=50)\n",
        "    plt.title(f'Ordinary Kriging Interpolation of {measurement_type_to_krig}')\n",
        "    plt.xlabel('Longitude')\n",
        "    plt.ylabel('Latitude')\n",
        "    plt.colorbar(label=f'{measurement_type_to_krig} Level')\n",
        "    plt.axis('equal')\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "    plt.close(fig_interpolation)\n",
        "    plots.append(fig_interpolation)\n",
        "\n",
        "    # Plot the variance (estimation error)\n",
        "    fig_variations = plt.figure(figsize=(10, 8))\n",
        "    contour_var = plt.contourf(grid_lon, grid_lat, ss, levels=20, cmap='plasma_r')\n",
        "    cbar_var = plt.colorbar(contour_var, label='Kriging Variance')\n",
        "    plt.scatter(kriging_longitudes, kriging_latitudes, c='black', edgecolor='white', s=50)\n",
        "    plt.title(f'Ordinary Kriging Variance for {measurement_type_to_krig}')\n",
        "    plt.xlabel('Longitude')\n",
        "    plt.ylabel('Latitude')\n",
        "    plt.axis('equal')\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "    plt.close(fig_variations)\n",
        "    plots.append(fig_variations)\n",
        "\n",
        "  return plots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qOpdKZNDTG8x"
      },
      "outputs": [],
      "source": [
        "def plot_kriging_at(year, month, data_source, measurement_type):\n",
        "    \"\"\"\n",
        "    Plots Ordinary Kriging interpolation for a given year and month,\n",
        "    using a specified data source and measurement type.\n",
        "\n",
        "    Args:\n",
        "        year (int): The year of the data.\n",
        "        month (int): The month of the data.\n",
        "        data_source (pd.DataFrame): The DataFrame containing the data\n",
        "                                     (either monitoring_df or biogis_df).\n",
        "        measurement_type (str): The type of measurement to krig\n",
        "                                (e.g., 'coliform_bacteria' or 'individuals').\n",
        "\n",
        "    Returns:\n",
        "        list: A list of matplotlib figure objects (interpolation and variance plots),\n",
        "              or [None, None] if not enough data points are available.\n",
        "    \"\"\"\n",
        "    if data_source is monitoring_df:\n",
        "        filtered_data = data_source[\n",
        "            (data_source['measurement_date'].dt.year == year) &\n",
        "            (data_source['measurement_date'].dt.month == month) &\n",
        "            (data_source['measurement_type'] == measurement_type)\n",
        "        ]\n",
        "\n",
        "        kriging_longitudes = []\n",
        "        kriging_latitudes = []\n",
        "        kriging_values = []\n",
        "\n",
        "        for station, coords in station_coords.items():\n",
        "            if station in filtered_data.columns and not pd.isna(filtered_data[station].iloc[0]):\n",
        "                kriging_longitudes.append(coords[0])\n",
        "                kriging_latitudes.append(coords[1])\n",
        "                kriging_values.append(filtered_data[station].iloc[0])\n",
        "\n",
        "        kriging_longitudes = np.array(kriging_longitudes)\n",
        "        kriging_latitudes = np.array(kriging_latitudes)\n",
        "        kriging_values = np.array(kriging_values)\n",
        "\n",
        "    elif data_source is occurences_df:\n",
        "        filtered_data = data_source[\n",
        "            (data_source['collection_date'].dt.year == year) &\n",
        "             (data_source['collection_date'].dt.month == month)\n",
        "        ]\n",
        "\n",
        "        aggregated_individuals = filtered_data.groupby(['longitude', 'latitude'])[measurement_type].sum().reset_index()\n",
        "        kriging_longitudes = aggregated_individuals['longitude'].values\n",
        "        kriging_latitudes = aggregated_individuals['latitude'].values\n",
        "        kriging_values = aggregated_individuals[measurement_type].values\n",
        "\n",
        "    else:\n",
        "        return [None, None] # Unsupported data source\n",
        "\n",
        "    plots = plot_ordinary_kriging(kriging_longitudes, kriging_latitudes, kriging_values, measurement_type)\n",
        "\n",
        "    if not plots:\n",
        "        return [None, None]\n",
        "    return plots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XnLpgvFwTjhn"
      },
      "outputs": [],
      "source": [
        "def plot_kriging_for_month_and_year(measurement_type, month, year):\n",
        "  data_source = occurences_df if measurement_type == 'individualCount' else monitoring_df\n",
        "  return plot_kriging_at(year, month, data_source, measurement_type)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Other"
      ],
      "metadata": {
        "id": "tXNW30ZUYted"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_density_heatmap(x_measure, y_measure):\n",
        "    \"\"\"\n",
        "    Generates a density heatmap of individual counts based on two selected environmental measures.\n",
        "\n",
        "    Args:\n",
        "        x_measure (str): The name of the environmental measure for the x-axis.\n",
        "        y_measure (str): The name of the environmental measure for the y-axis.\n",
        "\n",
        "    Returns:\n",
        "        plotly.graph_objects.Figure: The Plotly density heatmap figure.\n",
        "    \"\"\"\n",
        "    # Create a copy to avoid modifying the original merged_df\n",
        "    heatmap_df = merged_df.copy()\n",
        "\n",
        "    # Ensure the column exists before trying to plot\n",
        "    valid_measures = ['coliform_bacteria', 'specific_electrical_conductivity', 'opacity', 'ph_value', 'temperature']\n",
        "    if x_measure not in valid_measures or y_measure not in valid_measures:\n",
        "         print(f\"Error: Selected measure(s) '{x_measure}' or '{y_measure}' not found in data.\")\n",
        "         return plotly.graph_objects.Figure() # Return an empty figure or an informative message\n",
        "\n",
        "    num_bins = 10 # Define the number of bins\n",
        "\n",
        "    if x_measure == y_measure:\n",
        "        # Create bins for the single measure\n",
        "        heatmap_df[f'{x_measure}_bin'] = pd.cut(heatmap_df[x_measure], bins=num_bins)\n",
        "\n",
        "        # Group by the bins and sum the individual counts\n",
        "        binned_single_measure_data = heatmap_df.groupby(f'{x_measure}_bin')['individualCount'].sum().reset_index()\n",
        "\n",
        "        # Drop rows where binning resulted in NaNs\n",
        "        binned_single_measure_data.dropna(inplace=True)\n",
        "\n",
        "        # Convert bins to string for plotting\n",
        "        binned_single_measure_data[f'{x_measure}_str'] = binned_single_measure_data[f'{x_measure}_bin'].astype(str)\n",
        "\n",
        "\n",
        "        # Plot the sum of individual counts per bin using a bar plot\n",
        "        fig = px.bar(\n",
        "            binned_single_measure_data,\n",
        "            x=f'{x_measure}_str', # Use the string representation of the bin\n",
        "            y='individualCount',\n",
        "            labels={f'{x_measure}_str': x_measure.replace('_', ' ').title() + ' Bin',\n",
        "                    \"individualCount\": \"Total Individuals\"},\n",
        "            title=f\"Total Individuals per {x_measure.replace('_', ' ').title()} Bin\"\n",
        "        )\n",
        "        fig.update_xaxes(categoryorder='category ascending') # Ensure bins are ordered correctly\n",
        "        return fig\n",
        "\n",
        "\n",
        "    # Create bins for the selected measures (for heatmap)\n",
        "    heatmap_df[f'{x_measure}_bin'] = pd.cut(heatmap_df[x_measure], bins=num_bins)\n",
        "    heatmap_df[f'{y_measure}_bin'] = pd.cut(heatmap_df[y_measure], bins=num_bins)\n",
        "\n",
        "    # Convert bins to string for grouping and plotting\n",
        "    heatmap_df[f'{x_measure}_str'] = heatmap_df[f'{x_measure}_bin'].astype(str)\n",
        "    heatmap_df[f'{y_measure}_str'] = heatmap_df[f'{y_measure}_bin'].astype(str)\n",
        "\n",
        "\n",
        "    # Group by the string representation of the bins and sum the individual counts\n",
        "    binned_heatmap_data = heatmap_df.groupby([f'{x_measure}_str', f'{y_measure}_str'])['individualCount'].sum().reset_index()\n",
        "\n",
        "    # Drop rows where binning resulted in NaNs (this should be handled by dropping from heatmap_df earlier)\n",
        "    # binned_heatmap_data.dropna(inplace=True) # This might not be necessary if NaNs were dropped from heatmap_df\n",
        "\n",
        "\n",
        "    # Create the density heatmap using Plotly Express\n",
        "    fig = px.density_heatmap(\n",
        "        binned_heatmap_data,\n",
        "        x=f'{x_measure}_str', # Use the string representation of the bin column name\n",
        "        y=f'{y_measure}_str', # Use the string representation of the bin column name\n",
        "        z=\"individualCount\",\n",
        "        color_continuous_scale=\"Viridis\",\n",
        "        labels={f'{x_measure}_str': x_measure.replace('_', ' ').title() + ' Bin',\n",
        "                f'{y_measure}_str': y_measure.replace('_', ' ').title() + ' Bin',\n",
        "                \"individualCount\": \"Total Individuals\"},\n",
        "        title=f\"Total Individuals Density: {x_measure.replace('_', ' ').title()} vs {y_measure.replace('_', ' ').title()}\"\n",
        "    )\n",
        "\n",
        "    # Improve axis labels readability\n",
        "    fig.update_xaxes(categoryorder='category ascending')\n",
        "    fig.update_yaxes(categoryorder='category ascending')\n",
        "\n",
        "\n",
        "    return fig"
      ],
      "metadata": {
        "id": "SD95HE37a6mO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df[\"cond_bin\"] = pd.cut(merged_df[\"specific_electrical_conductivity\"], bins=10)\n",
        "merged_df[\"opac_bin\"] = pd.cut(merged_df[\"opacity\"], bins=10)\n",
        "\n",
        "heat_df = merged_df.copy()\n",
        "heat_df[\"cond_str\"] = heat_df[\"cond_bin\"].astype(str)\n",
        "heat_df[\"opac_str\"] = heat_df[\"opac_bin\"].astype(str)"
      ],
      "metadata": {
        "id": "KmZrZUEUYwTZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sum individual counts for each conductivity bin\n",
        "sum_by_conductivity_bin = heat_df.groupby('cond_bin')['individualCount'].sum().reset_index()\n",
        "\n",
        "# Sum individual counts for each opacity bin\n",
        "sum_by_opacity_bin = heat_df.groupby('opac_bin')['individualCount'].sum().reset_index()"
      ],
      "metadata": {
        "id": "9GS3JJHRY5Wc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16029a49-cd69-4a9b-d4f3-2bd20bff32ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-24-658654603>:2: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
            "  sum_by_conductivity_bin = heat_df.groupby('cond_bin')['individualCount'].sum().reset_index()\n",
            "<ipython-input-24-658654603>:5: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
            "  sum_by_opacity_bin = heat_df.groupby('opac_bin')['individualCount'].sum().reset_index()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the number of bins for each environmental variable\n",
        "num_bins = 10\n",
        "\n",
        "# Create bins for each environmental variable\n",
        "merged_df['conductivity_bin'] = pd.cut(merged_df['specific_electrical_conductivity'], bins=num_bins)\n",
        "merged_df['opacity_bin'] = pd.cut(merged_df['opacity'], bins=num_bins)\n",
        "merged_df['coliform_bacteria_bin'] = pd.cut(merged_df['coliform_bacteria'], bins=num_bins)\n",
        "\n",
        "# Group by the bins and sum the individual counts\n",
        "binned_3d_data = merged_df.groupby(['conductivity_bin', 'opacity_bin', 'coliform_bacteria_bin'])['individualCount'].sum().reset_index()\n",
        "\n",
        "# Rename the individuals column for clarity\n",
        "binned_3d_data_sorted = binned_3d_data.sort_values(by='individualCount', ascending=False)\n",
        "binned_3d_data_sorted_with_individuals = binned_3d_data_sorted[binned_3d_data_sorted['individualCount'] > 0]"
      ],
      "metadata": {
        "id": "8pLYPBY1Y6-2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3a3973c-7446-4620-c980-d0009ce5a595"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-1321195837>:10: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
            "  binned_3d_data = merged_df.groupby(['conductivity_bin', 'opacity_bin', 'coliform_bacteria_bin'])['individualCount'].sum().reset_index()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the minimum value of the 'coliform_bacteria' column in the eco_data DataFrame\n",
        "min_coliform_bacteria = merged_df['coliform_bacteria'].min()\n",
        "\n",
        "print(f\"The minimum value in the 'coliform_bacteria' column is: {min_coliform_bacteria}\")\n",
        "\n",
        "# Also check the data types of the column to ensure they are numeric\n",
        "print(f\"The data type of the 'coliform_bacteria' column is: {merged_df['coliform_bacteria'].dtype}\")\n",
        "\n",
        "# Display rows with values close to the minimum to see the context\n",
        "display(merged_df[merged_df['coliform_bacteria'] <= min_coliform_bacteria + 10].sort_values(by='coliform_bacteria'))\n",
        "\n",
        "sum_by_coliform_bacteria_bin = merged_df.groupby('coliform_bacteria_bin')['individualCount'].sum().reset_index()"
      ],
      "metadata": {
        "id": "t3WAUT-XY8zO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f68058e3-f24c-4d2a-b2fd-9c386ce96850"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The minimum value in the 'coliform_bacteria' column is: 17.196314285714287\n",
            "The data type of the 'coliform_bacteria' column is: float64\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "    year  month  coliform_bacteria   opacity  ph_value  \\\n",
              "30  2024      9          17.196314  3.427143    5966.0   \n",
              "\n",
              "    specific_electrical_conductivity  temperature  individualCount  \\\n",
              "30                          8.162857         65.3               43   \n",
              "\n",
              "          cond_bin         opac_bin conductivity_bin      opacity_bin  \\\n",
              "30  (7.154, 9.515]  (3.228, 23.322]   (7.154, 9.515]  (3.228, 23.322]   \n",
              "\n",
              "    coliform_bacteria_bin  \n",
              "30  (-920.986, 93835.477]  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-db8f2f15-3775-4828-a76b-704f82ada664\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>year</th>\n",
              "      <th>month</th>\n",
              "      <th>coliform_bacteria</th>\n",
              "      <th>opacity</th>\n",
              "      <th>ph_value</th>\n",
              "      <th>specific_electrical_conductivity</th>\n",
              "      <th>temperature</th>\n",
              "      <th>individualCount</th>\n",
              "      <th>cond_bin</th>\n",
              "      <th>opac_bin</th>\n",
              "      <th>conductivity_bin</th>\n",
              "      <th>opacity_bin</th>\n",
              "      <th>coliform_bacteria_bin</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>2024</td>\n",
              "      <td>9</td>\n",
              "      <td>17.196314</td>\n",
              "      <td>3.427143</td>\n",
              "      <td>5966.0</td>\n",
              "      <td>8.162857</td>\n",
              "      <td>65.3</td>\n",
              "      <td>43</td>\n",
              "      <td>(7.154, 9.515]</td>\n",
              "      <td>(3.228, 23.322]</td>\n",
              "      <td>(7.154, 9.515]</td>\n",
              "      <td>(3.228, 23.322]</td>\n",
              "      <td>(-920.986, 93835.477]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-db8f2f15-3775-4828-a76b-704f82ada664')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-db8f2f15-3775-4828-a76b-704f82ada664 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-db8f2f15-3775-4828-a76b-704f82ada664');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"sum_by_coliform_bacteria_bin = merged_df\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"year\",\n      \"properties\": {\n        \"dtype\": \"int32\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          2024\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"month\",\n      \"properties\": {\n        \"dtype\": \"int32\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          9\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"coliform_bacteria\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 17.196314285714287,\n        \"max\": 17.196314285714287,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          17.196314285714287\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"opacity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 3.4271428571428575,\n        \"max\": 3.4271428571428575,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          3.4271428571428575\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ph_value\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 5966.0,\n        \"max\": 5966.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          5966.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"specific_electrical_conductivity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 8.162857142857144,\n        \"max\": 8.162857142857144,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          8.162857142857144\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"temperature\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 65.3,\n        \"max\": 65.3,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          65.3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"individualCount\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 43,\n        \"max\": 43,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          43\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cond_bin\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"(7.154, 9.515]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"opac_bin\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"(3.228, 23.322]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"conductivity_bin\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"(7.154, 9.515]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"opacity_bin\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"(3.228, 23.322]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"coliform_bacteria_bin\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"(-920.986, 93835.477]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-26-3460137880>:12: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
            "  sum_by_coliform_bacteria_bin = merged_df.groupby('coliform_bacteria_bin')['individualCount'].sum().reset_index()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VwaLEoI1w42g"
      },
      "source": [
        "# Map Screen"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYe4dyX50cE8"
      },
      "source": [
        "Map of occurences - from the past, and future observations using a model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NnAJdmsDxyn4"
      },
      "source": [
        "## Logic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E-L6gauKw5Ud"
      },
      "outputs": [],
      "source": [
        "kishon_occurences_grouped = kishon_occurences.groupby(['species', 'month', 'year', 'latitude', 'longitude'])['individualCount'].sum().reset_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U__ncfouMJFz"
      },
      "outputs": [],
      "source": [
        "# Convert station_coords to a GeoDataFrame for spatial operations\n",
        "station_gdf = gpd.GeoDataFrame(\n",
        "  data={'station_name': list(station_coords.keys())},\n",
        "  geometry=[Point(lon, lat) for lon, lat in station_coords.values()],\n",
        "  crs=\"EPSG:4326\" # WGS84\n",
        ")\n",
        "\n",
        "# Project to a local CRS for accurate distance calculation (e.g., Israeli Grid EPSG:2039)\n",
        "station_gdf_proj = station_gdf.to_crs(epsg=2039)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t90qzZq5NEYH"
      },
      "outputs": [],
      "source": [
        "# Process measurements: Unpivot and then pivot to get opacity/conductivity columns\n",
        "measurements_long = kishon_measurements.melt(\n",
        "  id_vars=['measurement_type', 'units', 'measurement_date'],\n",
        "  var_name='station_name',\n",
        "  value_name='measurement_value',\n",
        "  value_vars=list(station_coords.keys())\n",
        ").dropna(subset=['measurement_value'])\n",
        "\n",
        "measurements_processed = measurements_long.pivot_table(\n",
        "  index=['station_name', 'measurement_date'],\n",
        "  columns='measurement_type',\n",
        "  values='measurement_value'\n",
        ").reset_index()\n",
        "\n",
        "measurements_processed['month'] = measurements_processed['measurement_date'].dt.month\n",
        "measurements_processed['year'] = measurements_processed['measurement_date'].dt.year\n",
        "\n",
        "station_name_to_coords = {name: {'latitude': lat, 'longitude': lon} for name, (lon, lat) in station_coords.items()}\n",
        "measurements_processed['station_latitude'] = measurements_processed['station_name'].map(lambda x: station_name_to_coords[x]['latitude'])\n",
        "measurements_processed['station_longitude'] = measurements_processed['station_name'].map(lambda x: station_name_to_coords[x]['longitude'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ho_5X1sWNX9G"
      },
      "outputs": [],
      "source": [
        "# Assign occurrences to Nearest Station\n",
        "gdf_occurrences = gpd.GeoDataFrame(\n",
        "  kishon_occurences_grouped,\n",
        "  geometry=gpd.points_from_xy(kishon_occurences_grouped['longitude'], kishon_occurences_grouped['latitude']),\n",
        "  crs=\"EPSG:4326\"\n",
        ")\n",
        "gdf_occurrences_proj = gdf_occurrences.to_crs(epsg=2039)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0kGihahKNoBE"
      },
      "outputs": [],
      "source": [
        "def find_nearest_station(point_geom, stations_gdf_proj):\n",
        "    distances = stations_gdf_proj.geometry.distance(point_geom)\n",
        "    nearest_idx = distances.idxmin()\n",
        "    return stations_gdf_proj.loc[nearest_idx, 'station_name']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DG-P0Y1SNuE1"
      },
      "outputs": [],
      "source": [
        "gdf_occurrences_proj['assigned_station_name'] = gdf_occurrences_proj.geometry.apply(\n",
        "  lambda x: find_nearest_station(x, station_gdf_proj)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "szkgi5PiNxHI"
      },
      "outputs": [],
      "source": [
        "# Merge DataFrames\n",
        "occurrences_assigned = pd.DataFrame(gdf_occurrences_proj.drop(columns='geometry'))\n",
        "\n",
        "integrated_df = pd.merge(\n",
        "  occurrences_assigned,\n",
        "  measurements_processed[['station_name', 'month', 'year', 'opacity', 'specific_electrical_conductivity', 'station_latitude', 'station_longitude']],\n",
        "  left_on=['assigned_station_name', 'month', 'year'],\n",
        "  right_on=['station_name', 'month', 'year'],\n",
        "  how='left'\n",
        ")\n",
        "\n",
        "integrated_df = integrated_df.rename(columns={\n",
        "  'station_latitude': 'mapped_latitude',\n",
        "  'station_longitude': 'mapped_longitude'\n",
        "})\n",
        "\n",
        "integrated_df.drop(columns=['station_name'], inplace=True)\n",
        "\n",
        "integrated_df['date'] = pd.to_datetime(integrated_df['year'].astype(str) + '-' + integrated_df['month'].astype(str) + '-01')\n",
        "integrated_df = integrated_df.set_index('date').sort_values(['species', 'assigned_station_name', 'latitude', 'longitude', 'date'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c5oBYRRYOCIa"
      },
      "outputs": [],
      "source": [
        "# Handle Missing Values in Integrated Data (e.g., if a measurement was missing)\n",
        "integrated_df['opacity'] = integrated_df['opacity'].fillna(integrated_df.groupby(['assigned_station_name', 'month'])['opacity'].transform('mean'))\n",
        "integrated_df['specific_electrical_conductivity'] = integrated_df['specific_electrical_conductivity'].fillna(integrated_df.groupby(['assigned_station_name', 'month'])['specific_electrical_conductivity'].transform('mean'))\n",
        "integrated_df['opacity'] = integrated_df['opacity'].fillna(integrated_df['opacity'].mean())\n",
        "integrated_df['specific_electrical_conductivity'] = integrated_df['specific_electrical_conductivity'].fillna(integrated_df['specific_electrical_conductivity'].mean())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x2-7QBfHOUSN"
      },
      "outputs": [],
      "source": [
        "# 2.1 Feature Engineering for the model\n",
        "integrated_df['species_station_id'] = integrated_df['species'] + '_' + integrated_df['assigned_station_name']\n",
        "\n",
        "integrated_df['previous_individualCount'] = integrated_df.groupby('species_station_id')['individualCount'].shift(1)\n",
        "integrated_df['previous_opacity'] = integrated_df.groupby('species_station_id')['opacity'].shift(1)\n",
        "integrated_df['previous_conductivity'] = integrated_df.groupby('species_station_id')['specific_electrical_conductivity'].shift(1)\n",
        "\n",
        "integrated_df.dropna(subset=['previous_individualCount', 'previous_opacity', 'previous_conductivity'], inplace=True)\n",
        "\n",
        "species_encoder = LabelEncoder()\n",
        "integrated_df['species_encoded'] = species_encoder.fit_transform(integrated_df['species'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FNwXv4b1OZzb"
      },
      "outputs": [],
      "source": [
        "features = [\n",
        "    'month', 'year', 'mapped_latitude', 'mapped_longitude', 'species_encoded',\n",
        "    'previous_individualCount', 'previous_opacity', 'previous_conductivity'\n",
        "]\n",
        "target = 'individualCount'\n",
        "\n",
        "X = integrated_df[features]\n",
        "y = integrated_df[target]\n",
        "\n",
        "# Train-Test Split (Time-based)\n",
        "train_end_date = integrated_df.index.max() - pd.DateOffset(months=12)\n",
        "\n",
        "X_train = X[integrated_df.index <= train_end_date]\n",
        "y_train = y[integrated_df.index <= train_end_date]\n",
        "\n",
        "X_test = X[integrated_df.index > train_end_date]\n",
        "y_test = y.loc[X_test.index]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nNy9CRNIOepf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "463e96b7-29ef-4a7a-d98c-47a6c53507bb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
              "             colsample_bylevel=None, colsample_bynode=None,\n",
              "             colsample_bytree=0.7, device=None, early_stopping_rounds=None,\n",
              "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "             gamma=None, grow_policy=None, importance_type=None,\n",
              "             interaction_constraints=None, learning_rate=0.05, max_bin=None,\n",
              "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "             max_delta_step=None, max_depth=6, max_leaves=None,\n",
              "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "             multi_strategy=None, n_estimators=200, n_jobs=-1,\n",
              "             num_parallel_tree=None, random_state=42, ...)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-1 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-1 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-1 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-1 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-1 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
              "             colsample_bylevel=None, colsample_bynode=None,\n",
              "             colsample_bytree=0.7, device=None, early_stopping_rounds=None,\n",
              "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "             gamma=None, grow_policy=None, importance_type=None,\n",
              "             interaction_constraints=None, learning_rate=0.05, max_bin=None,\n",
              "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "             max_delta_step=None, max_depth=6, max_leaves=None,\n",
              "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "             multi_strategy=None, n_estimators=200, n_jobs=-1,\n",
              "             num_parallel_tree=None, random_state=42, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>XGBRegressor</div></div><div><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
              "             colsample_bylevel=None, colsample_bynode=None,\n",
              "             colsample_bytree=0.7, device=None, early_stopping_rounds=None,\n",
              "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "             gamma=None, grow_policy=None, importance_type=None,\n",
              "             interaction_constraints=None, learning_rate=0.05, max_bin=None,\n",
              "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "             max_delta_step=None, max_depth=6, max_leaves=None,\n",
              "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "             multi_strategy=None, n_estimators=200, n_jobs=-1,\n",
              "             num_parallel_tree=None, random_state=42, ...)</pre></div> </div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "# Model Training (XGBoost Regressor)\n",
        "model = xgb.XGBRegressor(\n",
        "    objective='reg:squarederror',\n",
        "    n_estimators=200,\n",
        "    learning_rate=0.05,\n",
        "    max_depth=6,\n",
        "    subsample=0.7,\n",
        "    colsample_bytree=0.7,\n",
        "    random_state=42,\n",
        "    n_jobs=-1,\n",
        "    tree_method='hist'\n",
        ")\n",
        "\n",
        "model.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tEmgiS9pO2Rt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a19aa3d0-7054-411c-846d-1b994f365d2a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-38-3671373055>:26: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  historical_proportions = historical_proportions.groupby(['species', 'assigned_station_name'], group_keys=False).apply(normalize_proportions)\n"
          ]
        }
      ],
      "source": [
        "# 3.1 Calculate historical proportions for each original location within its species-station group\n",
        "historical_loc_counts = integrated_df.groupby(['species', 'latitude', 'longitude', 'assigned_station_name'])['individualCount'].mean().reset_index()\n",
        "historical_loc_counts = historical_loc_counts.rename(columns={'individualCount': 'avg_loc_individualCount'})\n",
        "\n",
        "historical_station_counts = integrated_df.groupby(['species', 'assigned_station_name'])['individualCount'].mean().reset_index()\n",
        "historical_station_counts = historical_station_counts.rename(columns={'individualCount': 'avg_station_total_individualCount'})\n",
        "\n",
        "historical_proportions = pd.merge(\n",
        "  historical_loc_counts,\n",
        "  historical_station_counts,\n",
        "  on=['species', 'assigned_station_name'],\n",
        "  how='left'\n",
        ")\n",
        "\n",
        "historical_proportions['proportion'] = historical_proportions.apply(\n",
        "  lambda row: row['avg_loc_individualCount'] / row['avg_station_total_individualCount'] if row['avg_station_total_individualCount'] > 0 else 0,\n",
        "  axis=1\n",
        ")\n",
        "\n",
        "def normalize_proportions(df_group):\n",
        "  total_proportion = df_group['proportion'].sum()\n",
        "  if total_proportion > 0:\n",
        "      df_group['proportion'] = df_group['proportion'] / total_proportion\n",
        "  return df_group\n",
        "\n",
        "historical_proportions = historical_proportions.groupby(['species', 'assigned_station_name'], group_keys=False).apply(normalize_proportions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R7bU7NpASSUt"
      },
      "outputs": [],
      "source": [
        "def get_forecasted_map_data(target_month, target_year, integrated_df_full, model, species_encoder, features, historical_proportions, progress=gr.Progress()):\n",
        "    \"\"\"\n",
        "    Forecasts individual counts for a specific future month/year and disaggregates them.\n",
        "\n",
        "    Args:\n",
        "        target_month (int): The month for which to generate the forecast (1-12).\n",
        "        target_year (int): The year for which to generate the forecast.\n",
        "        integrated_df_full (pd.DataFrame): The full integrated historical dataframe.\n",
        "        model (xgb.XGBRegressor): The trained XGBoost model.\n",
        "        species_encoder (LabelEncoder): The fitted LabelEncoder for species.\n",
        "        features (list): List of feature column names used by the model.\n",
        "        historical_proportions (pd.DataFrame): DataFrame with historical proportions for disaggregation.\n",
        "        progress (gr.Progress): Gradio Progress object for updating UI.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: A DataFrame with forecasted individual counts disaggregated to original\n",
        "                      locations, ready for mapping, or an error message if the date is invalid.\n",
        "    \"\"\"\n",
        "    last_known_date_global = integrated_df_full.index.max()\n",
        "    target_date = pd.to_datetime(f\"{target_year}-{target_month}-01\")\n",
        "\n",
        "    if target_date <= last_known_date_global:\n",
        "        return \"Error: Target date must be after the last known historical data (e.g., after \" + last_known_date_global.strftime('%Y-%m-%d') + \").\", None\n",
        "\n",
        "    # Calculate how many months into the future we need to forecast recursively\n",
        "    future_periods_to_target = (target_date.year - last_known_date_global.year) * 12 + (target_date.month - last_known_date_global.month)\n",
        "\n",
        "    future_forecast_results_list = []\n",
        "\n",
        "    # Get unique species and stations from the full historical data\n",
        "    data_for_month = integrated_df_full[integrated_df_full['month'] == target_month]\n",
        "    unique_species_stations = data_for_month.groupby(['species', 'assigned_station_name']).first().reset_index()\n",
        "    total_groups = len(unique_species_stations)\n",
        "\n",
        "    # Iterate through unique species-station combinations to forecast\n",
        "    for i, row_info in enumerate(unique_species_stations.iterrows()):\n",
        "        # Update progress bar\n",
        "        progress((i + 1) / total_groups, desc=f\"Forecasting {row_info[1]['species']} at {row_info[1]['assigned_station_name']}\")\n",
        "\n",
        "        species_orig_name = row_info[1]['species']\n",
        "        station_name = row_info[1]['assigned_station_name']\n",
        "\n",
        "        species_encoded_val = species_encoder.transform([species_orig_name])[0]\n",
        "\n",
        "        # Get the last known actual data point for this specific group (species, station)\n",
        "        # We need the last actual individualCount, opacity, and conductivity for this group.\n",
        "        # Ensure we pick the latest actual for this specific species-station combo, not just globally.\n",
        "        group_data_last_actual = integrated_df_full[\n",
        "            (integrated_df_full['species'] == species_orig_name) &\n",
        "            (integrated_df_full['assigned_station_name'] == station_name)\n",
        "        ].sort_index().iloc[-1] # Get the very last entry for this group\n",
        "\n",
        "        prev_individualCount_forecast = group_data_last_actual['individualCount']\n",
        "        prev_opacity_forecast = group_data_last_actual['opacity']\n",
        "        prev_conductivity_forecast = group_data_last_actual['specific_electrical_conductivity']\n",
        "\n",
        "        current_forecast_date = last_known_date_global\n",
        "\n",
        "        # We only need to generate predictions up to the target date\n",
        "        for p in range(1, future_periods_to_target + 1):\n",
        "            current_forecast_date = last_known_date_global + pd.DateOffset(months=p)\n",
        "            current_month = current_forecast_date.month\n",
        "            current_year = current_forecast_date.year\n",
        "\n",
        "            future_features_dict = {\n",
        "                'month': current_month,\n",
        "                'year': current_year,\n",
        "                'mapped_latitude': group_data_last_actual['mapped_latitude'],\n",
        "                'mapped_longitude': group_data_last_actual['mapped_longitude'],\n",
        "                'species_encoded': species_encoded_val,\n",
        "                'previous_individualCount': prev_individualCount_forecast,\n",
        "                'previous_opacity': prev_opacity_forecast,\n",
        "                'previous_conductivity': prev_conductivity_forecast\n",
        "            }\n",
        "\n",
        "            pred_input_future = pd.DataFrame([future_features_dict])\n",
        "            pred_input_future = pred_input_future[features]\n",
        "\n",
        "            current_future_prediction = model.predict(pred_input_future)[0]\n",
        "            current_future_prediction = max(0, int(np.ceil(current_future_prediction)))\n",
        "\n",
        "            # Store forecast if it's the target month, otherwise just update for next recursive step\n",
        "            if current_forecast_date == target_date:\n",
        "                future_forecast_results_list.append({\n",
        "                    'date': current_forecast_date,\n",
        "                    'species': species_orig_name,\n",
        "                    'assigned_station_name': station_name,\n",
        "                    'mapped_latitude': group_data_last_actual['mapped_latitude'],\n",
        "                    'mapped_longitude': group_data_last_actual['mapped_longitude'],\n",
        "                    'forecasted_individualCount': current_future_prediction\n",
        "                })\n",
        "\n",
        "            # Update values for the next iteration (recursive forecasting)\n",
        "            prev_individualCount_forecast = current_future_prediction\n",
        "            # Environmental features are assumed constant for future (no future data)\n",
        "\n",
        "\n",
        "    future_forecast_station_level_df = pd.DataFrame(future_forecast_results_list).set_index('date').sort_index()\n",
        "    if future_forecast_station_level_df.empty:\n",
        "        return f\"Error: No forecasts generated for {target_month}/{target_year}. Check data and target date.\", None\n",
        "\n",
        "    # --- Apply proportions to future forecasts and create final DataFrame ---\n",
        "    final_forecast_disaggregated_list = []\n",
        "    total_forecast = len(future_forecast_station_level_df)\n",
        "    disaggregation_count = 0\n",
        "\n",
        "    for idx, forecast_row in future_forecast_station_level_df.iterrows():\n",
        "        # Update progress for disaggregation phase using the counter\n",
        "        progress(disaggregation_count / total_forecast, desc=f\"Disaggregating {forecast_row['species']} at {forecast_row['assigned_station_name']}\")\n",
        "        disaggregation_count += 1\n",
        "\n",
        "        forecast_date = idx\n",
        "        forecast_species = forecast_row['species']\n",
        "        forecast_assigned_station = forecast_row['assigned_station_name']\n",
        "        total_forecasted_count_at_station = forecast_row['forecasted_individualCount']\n",
        "\n",
        "        relevant_proportions = historical_proportions[\n",
        "            (historical_proportions['species'] == forecast_species) &\n",
        "            (historical_proportions['assigned_station_name'] == forecast_assigned_station)\n",
        "        ]\n",
        "\n",
        "        if relevant_proportions.empty:\n",
        "            # Fallback if no historical original locations for this species-station combo\n",
        "            final_forecast_disaggregated_list.append({\n",
        "                'forecast_date': forecast_date,\n",
        "                'species': forecast_species,\n",
        "                'original_latitude': forecast_row['mapped_latitude'],\n",
        "                'original_longitude': forecast_row['mapped_longitude'],\n",
        "                'assigned_station_name': forecast_assigned_station,\n",
        "                'disaggregated_individualCount': total_forecasted_count_at_station\n",
        "            })\n",
        "            continue\n",
        "\n",
        "        for _, prop_row in relevant_proportions.iterrows():\n",
        "            disaggregated_count = total_forecasted_count_at_station * prop_row['proportion']\n",
        "            disaggregated_count = int(np.ceil(disaggregated_count))\n",
        "\n",
        "            final_forecast_disaggregated_list.append({\n",
        "                'forecast_date': forecast_date,\n",
        "                'species': forecast_species,\n",
        "                'original_latitude': prop_row['latitude'],\n",
        "                'original_longitude': prop_row['longitude'],\n",
        "                'assigned_station_name': forecast_assigned_station,\n",
        "                'disaggregated_individualCount': disaggregated_count\n",
        "            })\n",
        "\n",
        "    final_forecast_df = pd.DataFrame(final_forecast_disaggregated_list)\n",
        "    return final_forecast_df, None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NNXpLvbCf6Kv"
      },
      "outputs": [],
      "source": [
        "def create_map_per_month_and_year(month, year):\n",
        "  current_datetime = datetime.now()\n",
        "  # Check if the selected date is after the last available data in kishon_occurences_grouped\n",
        "  last_occurence_date = pd.to_datetime(kishon_occurences_grouped[['year', 'month']].agg(lambda x: f\"{x['year']}-{x['month']}-01\", axis=1)).max()\n",
        "  selected_date = pd.to_datetime(f\"{year}-{month}-01\")\n",
        "\n",
        "  if selected_date > last_occurence_date:\n",
        "    return \"Error: Please select a past month and year based on the available data (up to \" + last_occurence_date.strftime('%Y-%m') + \").\", None\n",
        "\n",
        "  filtered_data = kishon_occurences_grouped[\n",
        "    (kishon_occurences_grouped['month'] == month) &\n",
        "    (kishon_occurences_grouped['year'] == year)\n",
        "  ]\n",
        "\n",
        "  # If no data for the selected month and year, return an error message and an empty plot\n",
        "  if filtered_data.empty:\n",
        "      empty_plot_fig = create_sum_count_plot(pd.DataFrame(), title_suffix=f\"(No Historical Data for {month}/{year})\")\n",
        "      return f\"<div style='color: red;'>No occurrence data found for {month}/{year}.</div>\", empty_plot_fig\n",
        "\n",
        "\n",
        "  historical_data_for_plot = kishon_occurences_grouped[\n",
        "    (kishon_occurences_grouped['month'] <= month) &\n",
        "    (kishon_occurences_grouped['year'] <= year)\n",
        "  ].copy()\n",
        "\n",
        "  # Generate the plot for historical data up to the selected date\n",
        "  plot_fig = create_sum_count_plot(historical_data_for_plot, title_suffix=f\"(Historical up to {month}/{year})\")\n",
        "\n",
        "  latitudes = filtered_data['latitude']\n",
        "  longitudes = filtered_data['longitude']\n",
        "\n",
        "  average_latitude = sum(latitudes) / len(latitudes)\n",
        "  average_longitude = sum(longitudes) / len(longitudes)\n",
        "\n",
        "  m = folium.Map(location=(average_latitude, average_longitude), zoom_start=10)\n",
        "\n",
        "  def plotDot(point):\n",
        "    folium.CircleMarker(\n",
        "      location=[point['latitude'], point['longitude']],\n",
        "      radius=5,\n",
        "      fill=True,\n",
        "      fill_color='red',\n",
        "      fill_opacity=0.7,\n",
        "      tooltip=f\"Species: {point['species']}<br>Latitude: {point['latitude']}<br>Longitude: {point['longitude']}<br>Individuals Count: {point['individualCount']}\"\n",
        "    ).add_to(m)\n",
        "\n",
        "  filtered_data.apply(plotDot, axis=1)\n",
        "  return m._repr_html_(), plot_fig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6l--kUoKTeCl"
      },
      "outputs": [],
      "source": [
        "def create_future_map_per_month_and_year(month, year, progress=gr.Progress()):\n",
        "  current_datetime = datetime.now()\n",
        "  if (month <= kishon_occurences_grouped['month'].max() and year < kishon_occurences_grouped['year'].max()):\n",
        "    return \"Error: Please select a future month and year.\", None\n",
        "\n",
        "  # Pass the progress object\n",
        "  final_forecast_df, error_msg = get_forecasted_map_data(month, year, integrated_df, model, species_encoder, features, historical_proportions, progress=progress)\n",
        "\n",
        "  empty_plot_fig = create_sum_count_plot(pd.DataFrame(), title_suffix=\"(No Forecast Data)\")\n",
        "  if error_msg or final_forecast_df.empty:\n",
        "      return f\"<div style='color: red;'>{error_msg if error_msg else 'Error: No forecasts generated.'}</div>\", empty_plot_fig\n",
        "\n",
        "  if final_forecast_df.empty:\n",
        "      return f\"<div style='color: red;'>Error: No forecasts generated for {month}/{year}. Check data and target date.</div>\", empty_plot_fig\n",
        "\n",
        "  if len(final_forecast_df) == 0:\n",
        "      return \"<div style='color: red;'>No data points to display for the selected period.</div>\", empty_plot_fig\n",
        "\n",
        "  # 1. Prepare historical data (up to the last known date)\n",
        "  historical_data_for_plot = integrated_df.copy().reset_index() # 'date' is now a regular column\n",
        "  historical_data_for_plot = historical_data_for_plot[['date', 'individualCount', 'species']] # Select 'date' directly\n",
        "\n",
        "  # 2. Prepare forecasted data\n",
        "  forecast_data_for_plot = final_forecast_df.copy()\n",
        "  forecast_data_for_plot = forecast_data_for_plot.rename(columns={'forecast_date': 'date', 'disaggregated_individualCount': 'individualCount'})\n",
        "  forecast_data_for_plot = forecast_data_for_plot[['date', 'individualCount']] # Select relevant columns\n",
        "\n",
        "  # Combine historical and forecasted data\n",
        "  combined_data_for_plot = pd.concat([historical_data_for_plot, forecast_data_for_plot])\n",
        "\n",
        "  # Generate the plot\n",
        "  plot_fig = create_sum_count_plot(combined_data_for_plot, title_suffix=f\"(Historical & Forecasted up to {month}/{year})\")\n",
        "\n",
        "  latitudes = final_forecast_df['original_latitude']\n",
        "  longitudes = final_forecast_df['original_longitude']\n",
        "\n",
        "  average_latitude = sum(latitudes) / len(latitudes)\n",
        "  average_longitude = sum(longitudes) / len(longitudes)\n",
        "\n",
        "  m = folium.Map(location=(average_latitude, average_longitude), zoom_start=10)\n",
        "\n",
        "  unique_species_for_month = historical_data_for_plot[historical_data_for_plot['date'].dt.month == month]['species'].unique()\n",
        "\n",
        "  for _, row in final_forecast_df.iterrows():\n",
        "    if not(row['species'] in unique_species_for_month):\n",
        "      continue\n",
        "    radius = max(5, int(np.sqrt(row['disaggregated_individualCount']) * 0.5))\n",
        "    folium.CircleMarker(\n",
        "      location=[row['original_latitude'], row['original_longitude']],\n",
        "      radius=radius,\n",
        "      fill=True,\n",
        "      fill_color='red',\n",
        "      fill_opacity=0.7,\n",
        "      tooltip=f\"Species: {row['species']}<br>Latitude: {row['original_latitude']}<br>Longitude: {row['original_longitude']}<br>Forecasted Individuals Count: {row['disaggregated_individualCount']}\"\n",
        "    ).add_to(m)\n",
        "\n",
        "  map_html = m._repr_html_()\n",
        "  return map_html, plot_fig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qDWhVWRensIr"
      },
      "outputs": [],
      "source": [
        "# Updated plotting function to return a Figure object\n",
        "def create_sum_count_plot(df_to_plot, title_suffix=\"\"):\n",
        "  fig, ax = plt.subplots(figsize=(10, 5))\n",
        "\n",
        "  if df_to_plot.empty:\n",
        "    ax.text(0.5, 0.5, \"No data to plot\", horizontalalignment='center', verticalalignment='center', transform=ax.transAxes)\n",
        "    ax.set_title(f\"Total Individual Counts Over Time {title_suffix}\")\n",
        "    ax.set_xlabel(\"Date\")\n",
        "    ax.set_ylabel(\"Total Count\")\n",
        "    plt.tight_layout()\n",
        "    return fig\n",
        "\n",
        "  # Ensure 'date' is a proper datetime column\n",
        "  # Check 1: If 'date' column doesn't exist, try to get from index or create from year/month\n",
        "  if 'date' not in df_to_plot.columns:\n",
        "    if isinstance(df_to_plot.index, pd.DatetimeIndex):\n",
        "      df_to_plot = df_to_plot.reset_index().rename(columns={'index': 'date'})\n",
        "    elif 'year' in df_to_plot.columns and 'month' in df_to_plot.columns:\n",
        "      df_to_plot['date'] = pd.to_datetime(df_to_plot['year'].astype(str) + '-' + df_to_plot['month'].astype(str) + '-01')\n",
        "    else:\n",
        "      # Fallback if no identifiable date column/index\n",
        "      ax.text(0.5, 0.5, \"Date column missing for plotting\", horizontalalignment='center', verticalalignment='center', transform=ax.transAxes)\n",
        "      ax.set_title(f\"Total Individual Counts Over Time {title_suffix}\")\n",
        "      plt.tight_layout()\n",
        "      return fig\n",
        "\n",
        "  # Check 2: Ensure 'date' column is actually datetime type\n",
        "  if not pd.api.types.is_datetime64_any_dtype(df_to_plot['date']):\n",
        "    try:\n",
        "      df_to_plot['date'] = pd.to_datetime(df_to_plot['date'])\n",
        "    except Exception as e:\n",
        "      ax.text(0.5, 0.5, f\"Could not convert 'date' column to datetime: {e}\", horizontalalignment='center', verticalalignment='center', transform=ax.transAxes)\n",
        "      ax.set_title(f\"Total Individual Counts Over Time {title_suffix}\")\n",
        "      plt.tight_layout()\n",
        "      return fig\n",
        "\n",
        "\n",
        "  # Determine the count column name dynamically\n",
        "  count_col = None\n",
        "  if 'individualCount' in df_to_plot.columns:\n",
        "    count_col = 'individualCount'\n",
        "  elif 'disaggregated_individualCount' in df_to_plot.columns:\n",
        "    count_col = 'disaggregated_individualCount'\n",
        "  elif 'forecasted_individualCount' in df_to_plot.columns:\n",
        "    count_col = 'forecasted_individualCount'\n",
        "\n",
        "  if count_col is None:\n",
        "    ax.text(0.5, 0.5, \"Count column missing for plotting\", horizontalalignment='center', verticalalignment='center', transform=ax.transAxes)\n",
        "    ax.set_title(f\"Total Individual Counts Over Time {title_suffix}\")\n",
        "    plt.tight_layout()\n",
        "    return fig\n",
        "\n",
        "  # Check 3: Ensure count column is numeric\n",
        "  if not pd.api.types.is_numeric_dtype(df_to_plot[count_col]):\n",
        "    try:\n",
        "      df_to_plot[count_col] = pd.to_numeric(df_to_plot[count_col], errors='coerce')\n",
        "      df_to_plot.dropna(subset=[count_col], inplace=True) # Drop rows where conversion failed\n",
        "    except Exception as e:\n",
        "      ax.text(0.5, 0.5, f\"Could not convert '{count_col}' column to numeric: {e}\", horizontalalignment='center', verticalalignment='center', transform=ax.transAxes)\n",
        "      ax.set_title(f\"Total Individual Counts Over Time {title_suffix}\")\n",
        "      plt.tight_layout()\n",
        "      return fig\n",
        "\n",
        "  if df_to_plot.empty: # Check again if dropping NaNs made it empty\n",
        "    ax.text(0.5, 0.5, \"No numeric count data to plot after cleaning\", horizontalalignment='center', verticalalignment='center', transform=ax.transAxes)\n",
        "    ax.set_title(f\"Total Individual Counts Over Time {title_suffix}\")\n",
        "    plt.tight_layout()\n",
        "    return fig\n",
        "\n",
        "  df_to_plot['month_start'] = df_to_plot['date'].dt.to_period('M').dt.to_timestamp()\n",
        "  sum_counts = df_to_plot.groupby('month_start')[count_col].sum().reset_index()\n",
        "  sum_counts = sum_counts.rename(columns={count_col: 'total_count'})\n",
        "\n",
        "  sns.lineplot(data=sum_counts, x='month_start', y='total_count', marker='o', ax=ax)\n",
        "\n",
        "  ax.set_title(f\"Total Individual Counts Over Time {title_suffix}\")\n",
        "  ax.set_xlabel(\"Date\")\n",
        "  ax.set_ylabel(\"Total Count\")\n",
        "  ax.grid(True)\n",
        "  plt.tight_layout()\n",
        "  plt.close(fig)\n",
        "  return fig"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-7-QB9Gw8ik"
      },
      "source": [
        "# Graph and Info Screen"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XLNEXzah0laA"
      },
      "source": [
        "Graph of ecological data in the river, info about animals and plants there"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VF52Dwmlx6GH"
      },
      "source": [
        "## Logic"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5lN2Zui4TBMK"
      },
      "source": [
        "### Graph logic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mCEHF1oIRJk2"
      },
      "outputs": [],
      "source": [
        "def get_months_axis(start_year, start_month, end_year, end_month):\n",
        "  months = []\n",
        "\n",
        "  for year in range(start_year, end_year + 1):\n",
        "    if year == start_year and year == end_year:\n",
        "      start = start_month\n",
        "      end = end_month\n",
        "    elif year == start_year:\n",
        "      start = start_month\n",
        "      end = 12\n",
        "    elif year == end_year:\n",
        "      start = 1\n",
        "      end = end_month\n",
        "    else:\n",
        "      start = 1\n",
        "      end = 12\n",
        "\n",
        "    for month in range(start, end + 1):\n",
        "      months.append(str(year) + \"-\" + str(Month(month).name))\n",
        "\n",
        "  return months"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PloNwtA1RKYj"
      },
      "outputs": [],
      "source": [
        "def normalize_list(lst):\n",
        "  max_val = max(lst)\n",
        "  return [(x / max_val) if max_val else 0.5 for x in lst]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "COtjJph1ROa1"
      },
      "outputs": [],
      "source": [
        "def get_values_list_by_time_periods_and_measurement(start_year, start_month, end_year, end_month, measurement, station, file):\n",
        "  res_dict = {}\n",
        "\n",
        "  for year in range(start_year, end_year + 1):\n",
        "    if year == start_year and year == end_year:\n",
        "      start = start_month\n",
        "      end = end_month\n",
        "    elif year == start_year:\n",
        "      start = start_month\n",
        "      end = 12\n",
        "    elif year == end_year:\n",
        "      start = 1\n",
        "      end = end_month\n",
        "    else:\n",
        "      start = 1\n",
        "      end = 12\n",
        "\n",
        "    for month in range(start, end + 1):\n",
        "      station_year_month_filter = (file['year'] == year) & (file['month'] == month) & (file['station_name'] == station)\n",
        "\n",
        "      if not file.loc[station_year_month_filter].empty:\n",
        "        if measurement_list[0].value == measurement:\n",
        "          res_dict[(year, month)] = file.loc[station_year_month_filter, 'individuals'].iloc[0]\n",
        "        else:\n",
        "          res_dict[(year, month)] = file.loc[station_year_month_filter, measurement].iloc[0]\n",
        "  return res_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3J3GHfFZsA6p"
      },
      "outputs": [],
      "source": [
        "def are_dates_valid(start_year, end_year, start_month, end_month):\n",
        "    return (start_year, start_month) <= (end_year, end_month)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oJuUBwOaQpIj"
      },
      "outputs": [],
      "source": [
        "def generate_plot(start_year, end_year, start_month, end_month, station):\n",
        "    if not are_dates_valid(start_year, end_year, start_month, end_month):\n",
        "      return gr.Plot()\n",
        "\n",
        "    measurments_and_individuals_df = pd.read_csv(measurments_and_individuals_file)\n",
        "\n",
        "    individuals_data = get_values_list_by_time_periods_and_measurement(start_year, start_month, end_year, end_month, measurement_list[0].value, station, measurments_and_individuals_df)\n",
        "    if 0 == len(individuals_data):\n",
        "      return gr.Plot()\n",
        "    filtered_months = [f\"{year}-{Month(month).name}\" for (year, month) in individuals_data.keys()]\n",
        "\n",
        "    measurements = {measurement_list[0].value: individuals_data.values()}\n",
        "    for measurement in measurement_list[1:]:\n",
        "      measurement_data = get_values_list_by_time_periods_and_measurement(start_year, start_month, end_year, end_month, measurement.value, station, measurments_and_individuals_df)\n",
        "      if 0 == len(measurement_data):\n",
        "        return gr.Plot()\n",
        "      measurements[measurement.value] = normalize_list(list(measurement_data.values()))\n",
        "\n",
        "    # bar width and x-axis creation\n",
        "    x = np.arange(len(filtered_months))\n",
        "    bar_width = 0.1\n",
        "\n",
        "    # graph and y-axis creation\n",
        "    fig, ax1 = plt.subplots(figsize=(24, 6))\n",
        "    ax2 = ax1.twinx()\n",
        "\n",
        "    # bars creation\n",
        "    x_offset = x + (- measurements_size / 2) * bar_width\n",
        "    bars = [ax1.bar(x_offset, measurements[measurement_list[0].value], width=bar_width, color=color_list[0].value, label=measurement_list[0].value)]  # total populations (left axis)\n",
        "    for index in range(1, measurements_size):\n",
        "      x_offset = x + (index - measurements_size / 2) * bar_width\n",
        "      bars.append(ax2.bar(x_offset, measurements[measurement_list[index].value], width=bar_width, color=color_list[index].value, label=measurement_list[index].value))  # other measurements (right axis)\n",
        "\n",
        "    # axises labels\n",
        "    ax1.set_xlabel('Month')\n",
        "    ax1.set_ylabel('Total populations', color='gray')\n",
        "    ax2.set_ylabel('Normal values (0.0 – 1.0)', color='black')\n",
        "    ax1.set_xticks(x)\n",
        "    ax1.set_xticklabels(filtered_months)\n",
        "\n",
        "    # title and grid settings\n",
        "    plt.title('Correlation between environmental measurements and total populations accross months')\n",
        "    ax1.grid(True, axis='y', linestyle='--', alpha=0.7)\n",
        "\n",
        "    labels = [measurement.value for measurement in measurement_list]\n",
        "    colors = [color_list[color_index].value for color_index in range(measurements_size)]\n",
        "    legend_patches = [plt.Rectangle((0,0),1,1,color=c) for c in colors]\n",
        "    plt.legend(legend_patches, labels, loc='upper left')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.close(fig)\n",
        "    return fig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ZfqcM_caSUX"
      },
      "outputs": [],
      "source": [
        "station_list_str = [station.name for station in Station]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4tjsoSVyTIJM"
      },
      "source": [
        "### Info logic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sAuy1oOmPxRY"
      },
      "outputs": [],
      "source": [
        "kishon_occurences = pd.read_csv(kishon_occurences_data_file)\n",
        "species_list = list(kishon_occurences['species'].dropna().unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jWSWxxZcPmJW"
      },
      "outputs": [],
      "source": [
        "def fetch_species_info(species_name):\n",
        "    url = f\"https://en.wikipedia.org/api/rest_v1/page/summary/{species_name.replace(' ', '_')}\"\n",
        "    response = requests.get(url)\n",
        "    if response.status_code != 200:\n",
        "        return \"Not found\", None, \"No data available.\"\n",
        "\n",
        "    data = response.json()\n",
        "    title = data.get(\"title\", \"Unknown\")\n",
        "    image = data.get(\"thumbnail\", {}).get(\"source\", None)\n",
        "    summary = data.get(\"extract\", \"No summary available.\")\n",
        "    return title, image, summary"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_species_occurrence_map(species_name):\n",
        "    \"\"\"\n",
        "    Creates a Folium map showing occurrences for a specific species over time.\n",
        "\n",
        "    Args:\n",
        "        species_name (str): The name of the species to visualize.\n",
        "\n",
        "    Returns:\n",
        "        str: HTML representation of the Folium map.\n",
        "    \"\"\"\n",
        "    if not species_name:\n",
        "        return \"<div style='color: red;'>Please select a species to display the map.</div>\"\n",
        "\n",
        "    filtered_species_data = kishon_occurences_grouped[kishon_occurences_grouped['species'] == species_name].copy()\n",
        "\n",
        "    if filtered_species_data.empty:\n",
        "        return f\"<div style='color: red;'>No occurrence data found for {species_name}.</div>\"\n",
        "\n",
        "    # Sort by date to show progression (optional but can be nice)\n",
        "    filtered_species_data['date'] = pd.to_datetime(filtered_species_data['year'].astype(str) + '-' + filtered_species_data['month'].astype(str) + '-01')\n",
        "    filtered_species_data = filtered_species_data.sort_values('date')\n",
        "\n",
        "    # Center the map around the average location of occurrences for this species\n",
        "    average_latitude = filtered_species_data['latitude'].mean()\n",
        "    average_longitude = filtered_species_data['longitude'].mean()\n",
        "\n",
        "    m = folium.Map(location=(average_latitude, average_longitude), zoom_start=12)\n",
        "\n",
        "    # Add markers for each occurrence\n",
        "    for idx, row in filtered_species_data.iterrows():\n",
        "        occurrence_date = row['date'].strftime('%Y-%m') # Format date for tooltip\n",
        "        folium.CircleMarker(\n",
        "            location=[row['latitude'], row['longitude']],\n",
        "            radius=5,\n",
        "            color='blue',\n",
        "            fill=True,\n",
        "            fill_color='blue',\n",
        "            fill_opacity=0.6,\n",
        "            tooltip=f\"Date: {occurrence_date}<br>Individuals: {row['individualCount']}<br>Lat: {row['latitude']:.4f}<br>Lon: {row['longitude']:.4f}\"\n",
        "        ).add_to(m)\n",
        "\n",
        "    # Return the HTML representation of the map\n",
        "    return m._repr_html_()"
      ],
      "metadata": {
        "id": "FoI40k1Tdp2c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def update_graph_info_content(species_name):\n",
        "    \"\"\"\n",
        "    Updates the graph and info content, including the species map,\n",
        "    when a species is selected.\n",
        "    \"\"\"\n",
        "    title, image, summary = fetch_species_info(species_name)\n",
        "    species_map_html = create_species_occurrence_map(species_name)\n",
        "    return title, image, summary, species_map_html"
      ],
      "metadata": {
        "id": "T-7kT2G6eKPw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZgLkZsP0Ro0"
      },
      "source": [
        "# App"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2AI7qtY2cdXQ",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 650
        },
        "outputId": "4fd377d3-afb4-4534-d62c-646c36e9d431"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://e316d71c5b23dc60f4.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://e316d71c5b23dc60f4.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 53
        }
      ],
      "source": [
        "def navigate(screen_name):\n",
        "    \"\"\"Controls the visibility of content sections based on the selected screen.\"\"\"\n",
        "    return {\n",
        "        main_content: gr.update(visible=screen_name == \"Main\"),\n",
        "        hw2_content: gr.update(visible=screen_name == \"HW2\"),\n",
        "        map_content: gr.update(visible=screen_name == \"Map\"),\n",
        "        graph_info_content: gr.update(visible=screen_name == \"Graph and Info\")\n",
        "    }\n",
        "\n",
        "def show_historical_map():\n",
        "    \"\"\"Shows the historical map container and hides the future map container.\"\"\"\n",
        "    return gr.Column(visible=True), gr.Column(visible=False)\n",
        "\n",
        "def show_future_map():\n",
        "    \"\"\"Shows the future map container and hides the historical map container.\"\"\"\n",
        "    return gr.Column(visible=False), gr.Column(visible=True)\n",
        "\n",
        "\n",
        "with gr.Blocks() as full_app:\n",
        "    with gr.Row():\n",
        "        main_button = gr.Button(\"Home\")\n",
        "        map_button = gr.Button(\"Map\")\n",
        "        graph_info_button = gr.Button(\"Info\")\n",
        "        hw2_button = gr.Button(\"Data Analysis\")\n",
        "\n",
        "    # Define content columns with initial visibility\n",
        "    with gr.Column(visible=True) as main_content:\n",
        "        gr.Markdown(\n",
        "            \"\"\"\n",
        "            <div style=\"text-align: center\">\n",
        "\n",
        "            # 🌍EcoKishon🌳\n",
        "            ### Kishon River Ecological Data Analysis and Forecasting\n",
        "\n",
        "            Welcome to the Kishon River Ecological Data Analysis and Forecasting application.\n",
        "            This project explores ecological data from the Kishon River, applies various data\n",
        "            science techniques to understand patterns, and forecasts future species occurrences.\n",
        "\n",
        "            ---\n",
        "\n",
        "            </div>\n",
        "            \"\"\",\n",
        "            elem_id=\"centered-markdown\"\n",
        "        )\n",
        "\n",
        "        image = \"https://upload.wikimedia.org/wikipedia/commons/9/98/Park_Kishon%2C_Haifa_023.JPG\"\n",
        "        gr.Image(value=image, type=\"pil\", label=\"Kishon River\", show_label=True, width=512, height=384)\n",
        "\n",
        "        gr.Markdown(\n",
        "            \"\"\"\n",
        "            <div style=\"text-align: center\">\n",
        "\n",
        "            ## 🌱 What You Can Do\n",
        "            - 📊 Explore population data for various species over time\n",
        "            - 🧠 Graphically display environmental data from the Kishon River\n",
        "            - 🗺️ Visualize ecological data on interactive maps\n",
        "            - 🔍 Search for species and view detailed summaries\n",
        "\n",
        "            </div>\n",
        "\n",
        "            \"\"\",\n",
        "            elem_id=\"centered-markdown\"\n",
        "        )\n",
        "\n",
        "\n",
        "    with gr.Column(visible=False) as hw2_content:\n",
        "        gr.Markdown(\"\"\"\n",
        "            # PCA and Kriging Analysis\n",
        "            * This page includes some analyses on the **Kishon River ecological data**.\n",
        "            * The data includes **measurements** in the river and **observations** of species occurrences.\n",
        "\n",
        "            ## PCA:\n",
        "            * This analysis is done to reduce the **dimensionality of the data** and identify the **main drivers** of variation in the data.\n",
        "            * We identified 4 measurements that are the main drivers of variation in the data - **opacity, specific electrical conductivity, coliform bacteria and individuals**.\n",
        "\n",
        "            ## Kriging:\n",
        "            * This analysis is done to create **spatial heatmaps** showing predicted values across the **river area** for specific dates.\n",
        "            * We used **ordinary kriging** to create heatmaps for opacity, specific electrical conductivity and individuals.\n",
        "        \"\"\")\n",
        "\n",
        "        with gr.Row():\n",
        "            with gr.Column():\n",
        "                gr.Markdown(\"\"\"\n",
        "                ### PCA Biplot\n",
        "                * The plot shown here is a **biplot** of the principal components of the data.\n",
        "                \"\"\")\n",
        "                gr.Plot(biplot_pc1_pc2(), label=\"PCA Biplot\")\n",
        "\n",
        "            with gr.Column():\n",
        "                gr.Markdown(\"\"\"\n",
        "                ### Correlation Matrix\n",
        "                * This heatmap shows the correlation between the ecological variables.\n",
        "                \"\"\")\n",
        "                gr.Plot(correlation_matrix_heatmap(), label=\"Correlation Matrix Heatmap\")\n",
        "\n",
        "        with gr.Row():\n",
        "            gr.Markdown(\"## Summary Tables\")\n",
        "\n",
        "        with gr.Row():\n",
        "            with gr.Column():\n",
        "                gr.Markdown(\"### Individual Counts by Conductivity Bin\")\n",
        "                gr.DataFrame(value=sum_by_conductivity_bin, label=\"Conductivity Bin Summary\")\n",
        "\n",
        "            with gr.Column():\n",
        "                gr.Markdown(\"### Individual Counts by Opacity Bin\")\n",
        "                gr.DataFrame(value=sum_by_opacity_bin, label=\"Opacity Bin Summary\")\n",
        "\n",
        "        with gr.Row():\n",
        "            with gr.Column():\n",
        "                gr.Markdown(\"### Individual Counts by Coliform Bacteria Bin\")\n",
        "                gr.DataFrame(value=sum_by_coliform_bacteria_bin, label=\"Coliform Bacteria Bin Summary\")\n",
        "\n",
        "            with gr.Column():\n",
        "                gr.Markdown(\"### Binned 3D Data (Conductivity, Opacity, Coliform Bacteria)\")\n",
        "                gr.DataFrame(value=binned_3d_data_sorted_with_individuals, label=\"3D Binned Data Summary\")\n",
        "\n",
        "        # Add components for the interactive density heatmap\n",
        "        gr.Markdown(\"\"\"\n",
        "            ### Interactive Density Heatmap\n",
        "            * Select two environmental measures to visualize the density of individual counts.\n",
        "        \"\"\")\n",
        "        with gr.Row():\n",
        "            measure_choices = ['coliform_bacteria', 'specific_electrical_conductivity', 'opacity']\n",
        "            x_measure_dropdown = gr.Dropdown(choices=measure_choices, label=\"Select X-axis Measure\", value='specific_electrical_conductivity')\n",
        "            y_measure_dropdown = gr.Dropdown(choices=measure_choices, label=\"Select Y-axis Measure\", value='opacity')\n",
        "        with gr.Row():\n",
        "            generate_heatmap_button = gr.Button(\"Generate Density Heatmap\")\n",
        "        with gr.Row():\n",
        "            density_heatmap_plot = gr.Plot(label=\"Individual Counts Density Heatmap\")\n",
        "\n",
        "        # Link the button click to the generate_density_heatmap function\n",
        "        generate_heatmap_button.click(\n",
        "            fn=generate_density_heatmap,\n",
        "            inputs=[x_measure_dropdown, y_measure_dropdown],\n",
        "            outputs=[density_heatmap_plot]\n",
        "        )\n",
        "\n",
        "\n",
        "        with gr.Row():\n",
        "            gr.Markdown(\"\"\"\n",
        "                ### Kriging\n",
        "                * The plots shown here are kriging heatmaps for **opacity, specific electrical conductivity and individuals** for a specific month and year.\n",
        "                * Use the **sliders** to choose a month and year and the **dropdown** to choose the measurement to show kriging for.\n",
        "                * Click the **button** to generate the kriging heatmaps.\n",
        "                ### Notes:\n",
        "                * We must note that because of **lack of data**, some of the kriging heatmaps may not be generated correctly.\n",
        "                \"\"\")\n",
        "\n",
        "        with gr.Row():\n",
        "            month_slider = gr.Slider(minimum=1, maximum=12, value=1, step=1, label=\"Choose Month\")\n",
        "            year_slider = gr.Slider(minimum=2022, maximum=2024, value=2022, step=1, label=\"Choose Year\")\n",
        "            measurement_type_dropdown = gr.Dropdown(choices=['individualCount', 'opacity', 'specific_electrical_conductivity'], label=\"Choose measurement to show kriging for\")\n",
        "\n",
        "        with gr.Row():\n",
        "            generate_kriging_button = gr.Button(\"Generate Kriging for measurement\")\n",
        "\n",
        "        with gr.Row():\n",
        "            kriging_interpolation_plot = gr.Plot(label=\"Kriging Interpolation Plot\")\n",
        "            kriging_variance_plot = gr.Plot(label=\"Kriging Variance Plot\")\n",
        "\n",
        "        # Link the button click to the plotting function\n",
        "        generate_kriging_button.click(\n",
        "            fn=plot_kriging_for_month_and_year,\n",
        "            inputs=[measurement_type_dropdown, month_slider, year_slider],\n",
        "            outputs=[kriging_interpolation_plot, kriging_variance_plot]\n",
        "        )\n",
        "\n",
        "\n",
        "    with gr.Column(visible=False) as map_content:\n",
        "        with gr.Row():\n",
        "            gr.Markdown(\"\"\"\n",
        "              # Kishon River Species Occurrences Map\n",
        "              * This page includes **two maps**.\n",
        "              * You can view historical data or future predictions.\n",
        "            \"\"\")\n",
        "\n",
        "        with gr.Row():\n",
        "            show_historical_button = gr.Button(\"Show Historical Map\")\n",
        "            show_future_button = gr.Button(\"Show Forecast Map\")\n",
        "\n",
        "        with gr.Column(visible=True) as current_map_container:\n",
        "            gr.Markdown(\"## Historical Data Map\")\n",
        "            with gr.Row():\n",
        "                # Adjust historical year range based on data\n",
        "                min_hist_year = 2022\n",
        "                max_hist_year = 2025\n",
        "                month_slider_hist = gr.Slider(label=\"Month\", minimum=1, maximum=12, value=integrated_df.index[-1].month if not integrated_df.empty else 1, step=1)\n",
        "                year_slider_hist = gr.Slider(label=\"Year\", minimum=min_hist_year, maximum=max_hist_year, value=integrated_df.index[-1].year if not integrated_df.empty else 2022, step=1)\n",
        "            with gr.Row():\n",
        "                generate_map_button_hist = gr.Button(\"Generate Historical Map\")\n",
        "            with gr.Row():\n",
        "                map_html_hist = gr.HTML(label=\"Historical Map Display\")\n",
        "                plot_component_hist = gr.Plot(label=\"Historical Total Counts Over Time\")\n",
        "\n",
        "            generate_map_button_hist.click(\n",
        "                fn=create_map_per_month_and_year,\n",
        "                inputs=[month_slider_hist, year_slider_hist],\n",
        "                outputs=[map_html_hist, plot_component_hist]\n",
        "            )\n",
        "\n",
        "        with gr.Column(visible=False) as future_map_container:\n",
        "            current_datetime = datetime.now()\n",
        "            gr.Markdown(\"## Future Forecast Map\")\n",
        "            with gr.Row():\n",
        "                month_slider_future = gr.Slider(label=\"Month\", minimum=1, maximum=12, value=(current_datetime.month + 1) if current_datetime.month < 12 else 1, step=1)\n",
        "                year_slider_future = gr.Slider(label=\"Year\", minimum=current_datetime.year, maximum=(current_datetime.year + 3), value=current_datetime.year if current_datetime.month < 12 else current_datetime.year + 1, step=1)\n",
        "            with gr.Row():\n",
        "                generate_map_button_future = gr.Button(\"Generate Forecast Map\")\n",
        "            with gr.Row():\n",
        "                map_html_future = gr.HTML(label=\"Future Map Display\")\n",
        "                plot_component_future = gr.Plot(label=\"Combined Historical & Forecasted Total Counts Plot\")\n",
        "\n",
        "            generate_map_button_future.click(\n",
        "                fn=create_future_map_per_month_and_year,\n",
        "                inputs=[month_slider_future, year_slider_future],\n",
        "                outputs=[map_html_future, plot_component_future]\n",
        "            )\n",
        "\n",
        "        # Link new buttons to show/hide map containers\n",
        "        show_historical_button.click(\n",
        "            fn=show_historical_map,\n",
        "            inputs=[],\n",
        "            outputs=[current_map_container, future_map_container]\n",
        "        )\n",
        "        show_future_button.click(\n",
        "            fn=show_future_map,\n",
        "            inputs=[],\n",
        "            outputs=[current_map_container, future_map_container]\n",
        "        )\n",
        "\n",
        "\n",
        "    with gr.Column(visible=False) as graph_info_content:\n",
        "      gr.Markdown(\"## 🌱 Graph and Info Dashboard\")\n",
        "\n",
        "      with gr.Row():\n",
        "        start_year = gr.Slider(minimum=2022, maximum=2024, label=\"Start Year\", value=2022, step=1)\n",
        "        end_year = gr.Slider(minimum=2022, maximum=2024, label=\"End Year\", value=2024, step=1)\n",
        "        start_month = gr.Slider(minimum=1, maximum=12, label=\"Start Month\", value=1, step=1)\n",
        "        end_month = gr.Slider(minimum=1, maximum=12, label=\"End Month\", value=12, step=1)\n",
        "\n",
        "      with gr.Row():\n",
        "        station_dropdown = gr.Dropdown(choices=station_list_str, label=\"Choose a Station\", allow_custom_value=False, filterable=True)\n",
        "\n",
        "      with gr.Row():\n",
        "        plot_btn = gr.Button(\"Generate Graph\")\n",
        "\n",
        "      with gr.Row():\n",
        "        graph_output = gr.Plot()\n",
        "\n",
        "      plot_btn.click(fn=generate_plot,\n",
        "                    inputs=[start_year, end_year, start_month, end_month, station_dropdown],\n",
        "                    outputs=graph_output)\n",
        "\n",
        "      with gr.Row():\n",
        "        gr.Markdown(\"### 🐾 Search for a Species\")\n",
        "\n",
        "      with gr.Row():\n",
        "        species_dropdown = gr.Dropdown(choices=species_list, label=\"Choose a Species\", allow_custom_value=False, filterable=True)\n",
        "\n",
        "      with gr.Row():\n",
        "        info_title = gr.Textbox(label=\"Name\", interactive=False)\n",
        "\n",
        "      with gr.Row():\n",
        "        with gr.Column():\n",
        "          with gr.Row():\n",
        "            info_image = gr.Image(label=\"Image\")\n",
        "          with gr.Row():\n",
        "            info_summary = gr.Textbox(label=\"Summary\", lines=5, interactive=False)\n",
        "        with gr.Column():\n",
        "          species_map_html = gr.HTML(label=\"Species Map\")\n",
        "\n",
        "\n",
        "      # Update the change function for the species dropdown to also update the map\n",
        "      species_dropdown.change(\n",
        "          fn=update_graph_info_content,\n",
        "          inputs=species_dropdown,\n",
        "          outputs=[info_title, info_image, info_summary, species_map_html]\n",
        "      )\n",
        "\n",
        "      full_app.load(update_graph_info_content, inputs=species_dropdown, outputs=[info_title, info_image, info_summary, species_map_html])\n",
        "\n",
        "\n",
        "    # Link navigation buttons to the navigate function\n",
        "    main_button.click(\n",
        "        fn=navigate,\n",
        "        inputs=gr.State(\"Main\"),\n",
        "        outputs=[main_content, hw2_content, map_content, graph_info_content],\n",
        "    )\n",
        "    hw2_button.click(\n",
        "        fn=navigate,\n",
        "        inputs=gr.State(\"HW2\"),\n",
        "        outputs=[main_content, hw2_content, map_content, graph_info_content],\n",
        "    )\n",
        "    map_button.click(\n",
        "        fn=navigate,\n",
        "        inputs=gr.State(\"Map\"),\n",
        "        outputs=[main_content, hw2_content, map_content, graph_info_content],\n",
        "    )\n",
        "    graph_info_button.click(\n",
        "        fn=navigate,\n",
        "        inputs=gr.State(\"Graph and Info\"),\n",
        "        outputs=[main_content, hw2_content, map_content, graph_info_content],\n",
        "    )\n",
        "\n",
        "\n",
        "full_app.launch()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "t21r1DDMvdBh",
        "vT8wjUNkw0iM",
        "tF14hES_Q4SO",
        "Oy-LCxPZSbTD",
        "VwaLEoI1w42g",
        "z-7-QB9Gw8ik",
        "5lN2Zui4TBMK"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}